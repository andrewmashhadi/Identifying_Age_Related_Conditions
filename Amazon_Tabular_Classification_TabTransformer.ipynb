{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d232297",
   "metadata": {},
   "source": [
    "# Tabular classification with Amazon SageMaker TabTransformer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3a271",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccbac955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51216b",
   "metadata": {},
   "source": [
    "## First, we store the training and validation data in S3 as instructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aeea8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all paths to data from local storage location\n",
    "TRAIN_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'train.csv'\n",
    "TEST_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'test.csv'\n",
    "GREEKS_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'greeks.csv'\n",
    "\n",
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# train-validation split \n",
    "X_train_raw, X_val, y_train_raw, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "ros = RandomOverSampler(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = ros.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]\n",
    "\n",
    "# make uints just in case \n",
    "y_train.astype('uint8')\n",
    "y_val.astype('uint8')\n",
    "\n",
    "# create df for train and val as instructed by aws\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_val = pd.concat([y_val, X_val], axis=1)\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    os.mkdir('train')\n",
    "\n",
    "df_train.to_csv('train/data.csv', index=False)\n",
    "\n",
    "if not os.path.exists('validation'):\n",
    "    os.mkdir('validation')\n",
    "\n",
    "df_val.to_csv('validation/data.csv', index=False)\n",
    "\n",
    "\n",
    "# Upload the files to s3\n",
    "s3 = boto3.resource('s3')\n",
    "response = s3.meta.client.upload_file('train/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/train/data.csv')\n",
    "\n",
    "response = s3.meta.client.upload_file('validation/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/validation/data.csv')\n",
    "\n",
    "\n",
    "# remove files and directories locally\n",
    "os.remove('train/data.csv')\n",
    "os.remove('validation/data.csv')\n",
    "os.rmdir('train')\n",
    "os.rmdir('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f05d4",
   "metadata": {},
   "source": [
    "## Next, we set up SageMaker training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade4907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto3.session.Session(region_name='us-west-1'))\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_role = 'arn:aws:iam::378421839225:role/service-role/AmazonSageMaker-ExecutionRole-20230623T185897'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09049994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "train_model_id, train_model_version, train_scope = (\n",
    "    \"pytorch-tabtransformerclassification-model\",\n",
    "    \"*\",\n",
    "    \"training\",\n",
    ")\n",
    "training_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune. In tabular case, however, the pre-trained model tarball is dummy and fine-tune means training from scratch.\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47078a",
   "metadata": {},
   "source": [
    "### 2.2. Set Training Parameters\n",
    "\n",
    "---\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to train our tabular algorithm. To begin, let us create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training.\n",
    "\n",
    "The second set of parameters are algorithm specific training hyper-parameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a60a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = \"mypersonalprojectdata\"\n",
    "training_data_prefix = \"ICR-Data/train\"\n",
    "validation_data_prefix = \"ICR-Data/validation\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{data_bucket}/{training_data_prefix}\"\n",
    "validation_dataset_s3_path = f\"s3://{data_bucket}/{validation_data_prefix}\"\n",
    "\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"tabular-training\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07adda",
   "metadata": {},
   "source": [
    "---\n",
    "For algorithm specific hyper-parameters, we start by fetching python dictionary of the training hyper-parameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e426b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': '80', 'patience': '10', 'learning_rate': '0.001', 'batch_size': '256', 'input_dim': '32', 'n_blocks': '4', 'attn_dropout': '0.2', 'mlp_dropout': '0.1', 'frac_shared_embed': '0.25'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"n_epochs\"] = \"80\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fe56c",
   "metadata": {},
   "source": [
    "# We move on to train with automatic model tuning  \n",
    "\n",
    "We use a HyperparameterTuner object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71a58757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "use_amt = True\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.01, scaling_type=\"Auto\"),\n",
    "    \"batch_size\": CategoricalParameter([128, 256, 512]),\n",
    "    \"attn_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "    \"mlp_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00983ba",
   "metadata": {},
   "source": [
    "---\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3f3d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-{train_model_id}-training\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69bb3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_amt:\n\u001b[1;32m      2\u001b[0m     tuner \u001b[38;5;241m=\u001b[39m HyperparameterTuner(\n\u001b[1;32m      3\u001b[0m         tabular_estimator,\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         base_tuning_job_name\u001b[38;5;241m=\u001b[39mtraining_job_name,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_dataset_s3_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset_s3_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Launch a SageMaker Training job by passing s3 path of the training data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     tabular_estimator\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     17\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training_dataset_s3_path, \n\u001b[1;32m     18\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m: validation_dataset_s3_path}, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, job_name\u001b[38;5;241m=\u001b[39mtraining_job_name\n\u001b[1;32m     19\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pt/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:300\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pt/lib/python3.10/site-packages/sagemaker/tuner.py:1033\u001b[0m, in \u001b[0;36mHyperparameterTuner.fit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1033\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pt/lib/python3.10/site-packages/sagemaker/tuner.py:2337\u001b[0m, in \u001b[0;36m_TuningJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;124;03m\"\"\"Placeholder docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pt/lib/python3.10/site-packages/sagemaker/session.py:4342\u001b[0m, in \u001b[0;36mSession.wait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   4328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_tuning_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   4329\u001b[0m     \u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker hyperparameter tuning job to complete.\u001b[39;00m\n\u001b[1;32m   4330\u001b[0m \n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4340\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If the hyperparameter tuning job fails.\u001b[39;00m\n\u001b[1;32m   4341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4342\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43m_wait_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tuning_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4343\u001b[0m     _check_job_status(job, desc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameterTuningJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pt/lib/python3.10/site-packages/sagemaker/session.py:6495\u001b[0m, in \u001b[0;36m_wait_until\u001b[0;34m(callable_fn, poll)\u001b[0m\n\u001b[1;32m   6493\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6494\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll\n\u001b[0;32m-> 6495\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6496\u001b[0m     result \u001b[38;5;241m=\u001b[39m callable_fn()\n\u001b[1;32m   6497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   6498\u001b[0m     \u001b[38;5;66;03m# For initial 5 mins we accept/pass AccessDeniedException.\u001b[39;00m\n\u001b[1;32m   6499\u001b[0m     \u001b[38;5;66;03m# The reason is to await tag propagation to avoid false AccessDenied claims for an\u001b[39;00m\n\u001b[1;32m   6500\u001b[0m     \u001b[38;5;66;03m# access policy based on resource tags, The caveat here is for true AccessDenied\u001b[39;00m\n\u001b[1;32m   6501\u001b[0m     \u001b[38;5;66;03m# cases the routine will fail after 5 mins\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if use_amt:\n",
    "    tuner = HyperparameterTuner(\n",
    "        tabular_estimator,\n",
    "        \"LogLoss\",\n",
    "        hyperparameter_ranges,\n",
    "        [{\"Name\": \"LogLoss\", \"Regex\": \"metrics={'LogLoss': (\\\\S+)}\"}],\n",
    "        max_jobs=10,  # increase the max_jobs to achieve better performance from hyperparameter tuning\n",
    "        max_parallel_jobs=2,\n",
    "        objective_type=\"Minimize\",\n",
    "        base_tuning_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    tuner.fit({\"training\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, logs=True)\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    tabular_estimator.fit(\n",
    "        {\"training\": training_dataset_s3_path, \n",
    "         \"validation\": validation_dataset_s3_path}, logs=True, job_name=training_job_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb57b46",
   "metadata": {},
   "source": [
    "We now deploy and run inference on the Trained Tabular Model\n",
    "\n",
    "---\n",
    "\n",
    "In this section, you learn how to query an existing endpoint and make predictions of the examples you input. For each example, the model will output the probability of the sample for each class in the model. \n",
    "Next, the predicted class label is obtained by taking the class label with the maximum probability over others. Throughout the notebook, the examples are taken from the [Adult](https://archive.ics.uci.edu/ml/datasets/adult) test set.\n",
    "The dataset contains examples of census data to predict whether a person makes over 50K a year or not.\n",
    "\n",
    "\n",
    "We start by retrieving the jumpstart artifacts and deploy the `tabular_estimator` that we trained.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-inference-{train_model_id}\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = (tuner if use_amt else tabular_estimator).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdaa61",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we download a hold-out Adult test data from the S3 bucket for inference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpstart_assets_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "test_data_prefix = \"training-datasets/tabular_binary/test\"\n",
    "test_data_file_name = \"data.csv\"\n",
    "\n",
    "boto3.client(\"s3\").download_file(\n",
    "    jumpstart_assets_bucket, f\"{test_data_prefix}/{test_data_file_name}\", test_data_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ae192",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we read the Adult test data into pandas data frame, prepare the ground truth target and predicting features to send into the endpoint.\n",
    "\n",
    "Below is the screenshot of the first 5 examples in the Adult test set. All of the test examples with features\n",
    "from ```Feature_0``` to ```Feature_13``` are sent into the deployed model to get model predictions,\n",
    "to estimate the ground truth ```target``` column. For each test example, the model will output\n",
    "a vector of ```num_classes``` elements, where each element is the probability of the example for each class in the model.\n",
    "The ```num_classes``` is 2 in this case. Next, the predicted class label is obtained by taking the class label\n",
    "with the maximum probability over others. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f97980",
   "metadata": {},
   "outputs": [],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the data\n",
    "test_data = pd.read_csv(test_data_file_name, header=None)\n",
    "test_data.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, test_data.shape[1])]\n",
    "\n",
    "num_examples, num_columns = test_data.shape\n",
    "print(\n",
    "    f\"{bold}The test dataset contains {num_examples} examples and {num_columns} columns.{unbold}\\n\"\n",
    ")\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label, features = test_data.iloc[:, :1], test_data.iloc[:, 1:]\n",
    "\n",
    "print(f\"{bold}The first 5 observations of the data: {unbold} \\n\")\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a2d1c",
   "metadata": {},
   "source": [
    "---\n",
    "The following code queries the endpoint you have created to get the prediction for each test example. \n",
    "The `query_endpoint()` function returns an array-like of shape (num_examples, num_classes), where each row indicates\n",
    "the probability of the example for each class in the model. The num_classes is 2 in above test data.\n",
    "Next, the predicted class label is obtained by taking the class label with the maximum probability over others for each example. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_tabular_data):\n",
    "    # endpoint_name = endpoint_name\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_tabular_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_probabilities = model_predictions[\"probabilities\"]\n",
    "    return np.array(predicted_probabilities)\n",
    "\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint due to the large size of test data.\n",
    "batch_size = 1500\n",
    "predict_prob = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        features.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob = np.concatenate(predict_prob, axis=0)\n",
    "predict_label = np.argmax(predict_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0224fb1",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Prediction Results Returned from the Endpoint\n",
    "\n",
    "---\n",
    "We evaluate the predictions results returned from the endpoint by following two ways.\n",
    "\n",
    "* Visualize the predictions results by plotting the confusion matrix.\n",
    "\n",
    "* Measure the prediction results quantitatively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d331de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions results by plotting the confusion matrix.\n",
    "conf_matrix = confusion_matrix(y_true=ground_truth_label.values, y_pred=predict_label)\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va=\"center\", ha=\"center\", size=\"xx-large\")\n",
    "\n",
    "plt.xlabel(\"Predictions\", fontsize=18)\n",
    "plt.ylabel(\"Actuals\", fontsize=18)\n",
    "plt.title(\"Confusion Matrix\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the prediction results quantitatively.\n",
    "eval_accuracy = accuracy_score(ground_truth_label.values, predict_label)\n",
    "eval_f1 = f1_score(ground_truth_label.values, predict_label)\n",
    "\n",
    "print(\n",
    "    f\"{bold}Evaluation result on test data{unbold}:{newline}\"\n",
    "    f\"{bold}{accuracy_score.__name__}{unbold}: {eval_accuracy}{newline}\"\n",
    "    f\"{bold}F1 {unbold}: {eval_f1}{newline}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f57c5",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we delete the endpoint corresponding to the trained model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac60fe",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|tabtransformer_tabular|Amazon_Tabular_Classification_TabTransformer.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
