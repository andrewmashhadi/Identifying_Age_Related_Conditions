{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d232297",
   "metadata": {},
   "source": [
    "# Tabular classification with Amazon SageMaker TabTransformer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3a271",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbac955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51216b",
   "metadata": {},
   "source": [
    "## First, we store the training and validation data in S3 as instructed by AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeea8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all paths to data from local storage location\n",
    "TRAIN_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'train.csv'\n",
    "TEST_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'test.csv'\n",
    "GREEKS_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'greeks.csv'\n",
    "\n",
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# train-validation split \n",
    "X_train_raw, X_val, y_train_raw, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_val['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_val = X_val.fillna(value=X_train_raw.mean())\n",
    "\n",
    "X_train_raw['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_train_raw = X_train_raw.fillna(value=X_train_raw.mean())\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "oversample = SMOTE(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "np.random.seed(77)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]\n",
    "\n",
    "# make uints just in case \n",
    "y_train.astype('uint8')\n",
    "y_val.astype('uint8')\n",
    "\n",
    "# create df for train and val as instructed by aws\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "df_val = pd.concat([y_val, X_val], axis=1)\n",
    "df_val = df_val.dropna()\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    os.mkdir('train')\n",
    "\n",
    "df_train.to_csv('train/data.csv', index=False, header=False)\n",
    "\n",
    "if not os.path.exists('validation'):\n",
    "    os.mkdir('validation')\n",
    "\n",
    "df_val.to_csv('validation/data.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "# Upload the files to s3\n",
    "s3 = boto3.resource('s3')\n",
    "response = s3.meta.client.upload_file('train/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/train/data.csv')\n",
    "\n",
    "response = s3.meta.client.upload_file('validation/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/validation/data.csv')\n",
    "\n",
    "\n",
    "# remove files and directories locally\n",
    "os.remove('train/data.csv')\n",
    "os.remove('validation/data.csv')\n",
    "os.rmdir('train')\n",
    "os.rmdir('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f05d4",
   "metadata": {},
   "source": [
    "## Next, we set up a SageMaker training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade4907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto3.session.Session(region_name='us-west-1'))\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_role = 'arn:aws:iam::378421839225:role/service-role/AmazonSageMaker-ExecutionRole-20230623T185897'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09049994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "train_model_id, train_model_version, train_scope = (\n",
    "    \"pytorch-tabtransformerclassification-model\",\n",
    "    \"*\",\n",
    "    \"training\",\n",
    ")\n",
    "training_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune. In tabular case, however, the pre-trained model tarball is dummy and fine-tune means training from scratch.\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47078a",
   "metadata": {},
   "source": [
    "### Set Training Parameters\n",
    "\n",
    "---\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to train our tabular algorithm. To begin, we create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training.\n",
    "\n",
    "The second set of parameters are model, or algorithm, specific training hyperparameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a60a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = \"mypersonalprojectdata\"\n",
    "training_data_prefix = \"ICR-Data/train\"\n",
    "validation_data_prefix = \"ICR-Data/validation\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{data_bucket}/{training_data_prefix}\"\n",
    "validation_dataset_s3_path = f\"s3://{data_bucket}/{validation_data_prefix}\"\n",
    "\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"tabular-training\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07adda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the model specific specific hyperparameters, we start by fetching a python dictionary of the training hyperparameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e426b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': '15', 'patience': '10', 'learning_rate': '0.001', 'batch_size': '256', 'input_dim': '32', 'n_blocks': '4', 'attn_dropout': '0.2', 'mlp_dropout': '0.1', 'frac_shared_embed': '0.25'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# Override the number of epochs hyperparameter with custom values\n",
    "hyperparameters[\"n_epochs\"] = \"15\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fe56c",
   "metadata": {},
   "source": [
    "# We move on to train with automatic model tuning  \n",
    "\n",
    "We use a HyperparameterTuner object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71a58757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "use_amt = True\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.01, scaling_type=\"Auto\"),\n",
    "    \"batch_size\": CategoricalParameter([128, 256, 512]),\n",
    "    \"attn_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "    \"mlp_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00983ba",
   "metadata": {},
   "source": [
    "---\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3f3d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-{train_model_id}-training\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=1200,\n",
    "    max_retry_attempts=3,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69bb3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................!\n"
     ]
    }
   ],
   "source": [
    "# tune hyper-parameters with instances in AWS\n",
    "tuner = HyperparameterTuner(\n",
    "    tabular_estimator,\n",
    "    \"f1_score\",\n",
    "    hyperparameter_ranges,\n",
    "    [{\"Name\": \"f1_score\", \"Regex\": \"metrics={'f1': (\\\\S+)}\"}],\n",
    "    max_jobs=10,  # increase the max_jobs to achieve better performance from hyperparameter tuning\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type=\"Maximize\",\n",
    "    base_tuning_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "tuner.fit({\"training\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82a0adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best training job: jumpstart-pytorch-ta-230702-1232-008-df442c61\n"
     ]
    }
   ],
   "source": [
    "print(f'The best training job: {tuner.best_training_job()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46064452",
   "metadata": {},
   "source": [
    "The \"best\" hyperparameters can be seen on the AWS console. The following is from the best training job (003) with the highest `f1_score` of 0.8084999918937683:\n",
    "\n",
    "- `attn_dropout=0.23174447846243657`\n",
    "- `batch_size=128`\n",
    "- `frac_shared_embed=\"0.25\"`\n",
    "- `input_dim=\"32\"`\n",
    "- `learning_rate=0.0015378552188176709`\n",
    "- `mlp_dropout=0.530977533537545`\n",
    "- `n_blocks=\"4\"`\n",
    "- `n_epochs=\"15\"`\n",
    "- `patience=\"10\"`\n",
    "- `sagemaker_container_log_level=20`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb57b46",
   "metadata": {},
   "source": [
    "We now deploy and run inference on the trained TabTransformer model for the ICR validation data to store the predictions to use in other ensemble models.\n",
    "\n",
    "---\n",
    "\n",
    "The model will output the probability of the sample for each class in the model (2 classes). We start by retrieving the jumpstart artifacts and deploying the `tuner` that we trained.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08f4cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-07-02 19:38:22 Starting - Found matching resource for reuse\n",
      "2023-07-02 19:38:22 Downloading - Downloading input data\n",
      "2023-07-02 19:38:22 Training - Training image download completed. Training in progress.\n",
      "2023-07-02 19:38:22 Uploading - Uploading generated training model\n",
      "2023-07-02 19:38:22 Completed - Resource retained for reuse\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-inference-{train_model_id}\")\n",
    "\n",
    "# Use estimator with best hyperparameters from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33f97980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe test dataset contains 113 examples and 57 columns.\u001b[0m\n",
      "\n",
      "\u001b[1mThe first 5 observations of the data: \u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_47</th>\n",
       "      <th>Feature_48</th>\n",
       "      <th>Feature_49</th>\n",
       "      <th>Feature_50</th>\n",
       "      <th>Feature_51</th>\n",
       "      <th>Feature_52</th>\n",
       "      <th>Feature_53</th>\n",
       "      <th>Feature_54</th>\n",
       "      <th>Feature_55</th>\n",
       "      <th>Feature_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478576</td>\n",
       "      <td>5192.25520</td>\n",
       "      <td>194.576478</td>\n",
       "      <td>13.230384</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>7.290957</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.705080</td>\n",
       "      <td>8.588216</td>\n",
       "      <td>...</td>\n",
       "      <td>10.690335</td>\n",
       "      <td>1.85861</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>12.418170</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>434.357883</td>\n",
       "      <td>34.411808</td>\n",
       "      <td>36.769312</td>\n",
       "      <td>0.050038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1.096024</td>\n",
       "      <td>4348.11080</td>\n",
       "      <td>546.489750</td>\n",
       "      <td>72.469800</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.167092</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>13.381312</td>\n",
       "      <td>...</td>\n",
       "      <td>5.760795</td>\n",
       "      <td>2.02884</td>\n",
       "      <td>0.182871</td>\n",
       "      <td>12.283291</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2184.856740</td>\n",
       "      <td>33.204344</td>\n",
       "      <td>40.169496</td>\n",
       "      <td>0.077344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307656</td>\n",
       "      <td>3039.47402</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.534221</td>\n",
       "      <td>8.715528</td>\n",
       "      <td>5.262246</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>11.665002</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>7.534620</td>\n",
       "      <td>139.519779</td>\n",
       "      <td>10093.114350</td>\n",
       "      <td>30.456385</td>\n",
       "      <td>56.463116</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1.307538</td>\n",
       "      <td>8922.64648</td>\n",
       "      <td>198.478110</td>\n",
       "      <td>123.582688</td>\n",
       "      <td>13.380066</td>\n",
       "      <td>9.231078</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>16.404106</td>\n",
       "      <td>28.561792</td>\n",
       "      <td>...</td>\n",
       "      <td>6.015965</td>\n",
       "      <td>0.71224</td>\n",
       "      <td>0.331877</td>\n",
       "      <td>10.101972</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>4973.463261</td>\n",
       "      <td>46.062259</td>\n",
       "      <td>47.428966</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>4773.60488</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>8.368094</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.587895</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.577022</td>\n",
       "      <td>6.718768</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811895</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>14.669254</td>\n",
       "      <td>188.923924</td>\n",
       "      <td>7886.435724</td>\n",
       "      <td>29.485204</td>\n",
       "      <td>63.986216</td>\n",
       "      <td>0.231559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target  Feature_1   Feature_2   Feature_3   Feature_4  Feature_5  \\\n",
       "49        1   0.478576  5192.25520  194.576478   13.230384   8.138688   \n",
       "581       0   1.096024  4348.11080  546.489750   72.469800   8.138688   \n",
       "82        0   0.307656  3039.47402   85.200147   14.534221   8.715528   \n",
       "109       1   1.307538  8922.64648  198.478110  123.582688  13.380066   \n",
       "605       0   0.145282  4773.60488   85.200147    8.368094   8.138688   \n",
       "\n",
       "     Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_47  Feature_48  \\\n",
       "49    7.290957   0.025578   9.705080   8.588216  ...   10.690335     1.85861   \n",
       "581   3.167092   0.102921   3.396778  13.381312  ...    5.760795     2.02884   \n",
       "82    5.262246   0.031668  11.665002   1.229900  ...    0.173229     0.49706   \n",
       "109   9.231078   0.025578  16.404106  28.561792  ...    6.015965     0.71224   \n",
       "605   3.587895   0.025578   8.577022   6.718768  ...    3.811895     0.49706   \n",
       "\n",
       "     Feature_49  Feature_50  Feature_51    Feature_52  Feature_53  Feature_54  \\\n",
       "49     0.067730   12.418170   72.611063    434.357883   34.411808   36.769312   \n",
       "581    0.182871   12.283291   72.611063   2184.856740   33.204344   40.169496   \n",
       "82     0.067730    7.534620  139.519779  10093.114350   30.456385   56.463116   \n",
       "109    0.331877   10.101972   72.611063   4973.463261   46.062259   47.428966   \n",
       "605    0.067730   14.669254  188.923924   7886.435724   29.485204   63.986216   \n",
       "\n",
       "     Feature_55  Feature_56  \n",
       "49     0.050038           1  \n",
       "581    0.077344           1  \n",
       "82    21.978000           0  \n",
       "109    0.027720           1  \n",
       "605    0.231559           1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up training data for predictions\n",
    "df_train.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, df_train.shape[1])]\n",
    "\n",
    "num_examples_train, num_columns_train = df_train.shape\n",
    "print(\n",
    "    f\"{bold}The test dataset contains {num_examples} examples and {num_columns} columns.{unbold}\\n\"\n",
    ")\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label_train, features_train = df_train.iloc[:, :1], df_train.iloc[:, 1:]\n",
    "\n",
    "print(f\"{bold}The first 5 observations of the data: {unbold} \\n\")\n",
    "df_train.head(5)\n",
    "\n",
    "# set up validation data for predictions\n",
    "df_val.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, df_val.shape[1])]\n",
    "\n",
    "num_examples, num_columns = df_val.shape\n",
    "print(\n",
    "    f\"{bold}The test dataset contains {num_examples} examples and {num_columns} columns.{unbold}\\n\"\n",
    ")\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label, features = df_val.iloc[:, :1], df_val.iloc[:, 1:]\n",
    "\n",
    "print(f\"{bold}The first 5 observations of the data: {unbold} \\n\")\n",
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a2d1c",
   "metadata": {},
   "source": [
    "---\n",
    "The following code queries the endpoint we have created to get the predictions for the validation data. \n",
    "The `query_endpoint()` function returns an array-like of shape `(num_examples, num_classes)`, where each row indicates\n",
    "the probability of each class in the model. The `num_classes` is 2 in above test data.\n",
    "In addition, the predicted class label is obtained by taking the class label with the maximum probability over others for each example. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbc8fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_tabular_data):\n",
    "    # endpoint_name = endpoint_name\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_tabular_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_probabilities = model_predictions[\"probabilities\"]\n",
    "    return np.array(predicted_probabilities)\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint due to the large size of test data.\n",
    "batch_size = 1500\n",
    "predict_prob_train = []\n",
    "for i in np.arange(0, num_examples_train, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        features_train.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob_train.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob_train = np.concatenate(predict_prob, axis=0)\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint due to the large size of test data.\n",
    "batch_size = 1500\n",
    "predict_prob = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        features.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob = np.concatenate(predict_prob, axis=0)\n",
    "predict_label = np.argmax(predict_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0224fb1",
   "metadata": {},
   "source": [
    "## Evaluate the Validation Results Returned from the Endpoint\n",
    "\n",
    "---\n",
    "We evaluate the predictions returned from the endpoint by following two ways.\n",
    "\n",
    "* Visualize the predictions results by plotting the confusion matrix.\n",
    "\n",
    "* Evaluate the balanced logarithmic loss (as evaluated in the ICR -- Kaggle competition), along with a few other performance metrics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03d331de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the predictions results by plotting the confusion matrix.\n",
    "conf_matrix = confusion_matrix(y_true=ground_truth_label.values, y_pred=predict_label)\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va=\"center\", ha=\"center\", size=\"xx-large\")\n",
    "\n",
    "plt.xlabel(\"Predictions\", fontsize=18)\n",
    "plt.ylabel(\"Actuals\", fontsize=18)\n",
    "plt.title(\"Confusion Matrix\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d2d2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mEvaluation result on test data\u001b[0m:\n",
      "\u001b[1maccuracy_score\u001b[0m: 0.9203539823008849\n",
      "\u001b[1mF1 \u001b[0m: 0.8085106382978723\n",
      "\u001b[1mLog-Loss \u001b[0m: 0.24488367050503163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bal_log_loss(p, y):\n",
    "    ind0 = np.where(y==0)[0]\n",
    "    ind1 = np.where(y==1)[0]\n",
    "    \n",
    "    N0 = len(ind0)\n",
    "    N1 = len(ind1)\n",
    "    \n",
    "    y0 = (y==0).astype(int)\n",
    "    y1 = y.astype(int)\n",
    "    \n",
    "    return (- np.sum(y0*np.log(p[:, 0]))/N0 - np.sum(y1*np.log(p[:, 1]))/N1) / 2\n",
    "\n",
    "\n",
    "# Measure the prediction results quantitatively.\n",
    "eval_accuracy = accuracy_score(ground_truth_label.values, predict_label)\n",
    "eval_f1 = f1_score(ground_truth_label.values, predict_label)\n",
    "eval_log_loss = bal_log_loss(predict_prob, np.squeeze(ground_truth_label.values, axis=(1,)))\n",
    "\n",
    "print(\n",
    "    f\"{bold}Evaluation result on test data{unbold}:{newline}\"\n",
    "    f\"{bold}{accuracy_score.__name__}{unbold}: {eval_accuracy}{newline}\"\n",
    "    f\"{bold}F1 {unbold}: {eval_f1}{newline}\"\n",
    "    f\"{bold}Log-Loss {unbold}: {eval_log_loss}{newline}\"\n",
    ")\n",
    "\n",
    "# store the training-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob_train).to_csv(\"train_pred_probs/amzn-tab-trans.csv\", header=True, index=False)\n",
    "\n",
    "# store the validation-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob).to_csv(\"val_pred_probs/amzn-tab-trans.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f57c5",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we delete the endpoint corresponding to the trained model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ff6901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe294fb",
   "metadata": {},
   "source": [
    "# Predictions for Test Set Submission\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "Using the reported hyperparameters for *jumpstart-pytorch-ta-230701-1231-003-c17981ed*, we retrain the estimator with all of the training data. Since our training data is already fairly small, this is done to not waste the relatively training data. \n",
    "\n",
    "First, we reorganize the training data such that the entire set of data is used to train and only the training data is considered during \"validation\". \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "085f0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# fill NaNs\n",
    "X['EJ_B'].fillna(value=X['EJ_B'].mode())\n",
    "X = X.fillna(value=X.mean())\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "oversample = SMOTE(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X, y)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]\n",
    "\n",
    "# make uints just in case \n",
    "y_train.astype('uint8')\n",
    "\n",
    "# create df for train and val (should be the same in this case)\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "df_val = pd.concat([y_train, X_train], axis=1)\n",
    "\n",
    "df_val = df_val.dropna()\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    os.mkdir('train')\n",
    "\n",
    "df_train.to_csv('train/data.csv', index=False, header=False)\n",
    "\n",
    "if not os.path.exists('validation'):\n",
    "    os.mkdir('validation')\n",
    "\n",
    "df_val.to_csv('validation/data.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "# Upload the files to s3\n",
    "s3 = boto3.resource('s3')\n",
    "response = s3.meta.client.upload_file('train/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/train/data.csv')\n",
    "\n",
    "response = s3.meta.client.upload_file('validation/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/validation/data.csv')\n",
    "\n",
    "\n",
    "# remove files and directories locally\n",
    "os.remove('train/data.csv')\n",
    "os.remove('validation/data.csv')\n",
    "os.rmdir('train')\n",
    "os.rmdir('validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aff47a",
   "metadata": {},
   "source": [
    "Now we begin training with all of the available data, using the previously found \"optimal\" hyperparameters from tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd51492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: jumpstart-pytorch-tabtransformerclassif-2023-07-04-07-01-15-639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-04 07:01:16 Starting - Starting the training job......\n",
      "2023-07-04 07:02:01 Starting - Preparing the instances for training......\n",
      "2023-07-04 07:03:16 Downloading - Downloading input data\n",
      "2023-07-04 07:03:16 Training - Downloading the training image......\n",
      "2023-07-04 07:04:18 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:19,464 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:19,466 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:19,475 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:19,477 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:21,005 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/aiosignal/aiosignal-1.2.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/blis/blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/catalogue/catalogue-2.0.7-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/cramjam/cramjam-2.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/cymem/cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/distlib/distlib-0.3.4-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/einops/einops-0.4.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/fastparquet/fastparquet-0.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/filelock/filelock-3.7.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/frozenlist/frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/gensim/gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/grpcio/grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/importlib_resources/importlib_resources-5.7.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/imutils/imutils-0.5.4.tar.gz\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mProcessing ./lib/langcodes/langcodes-3.3.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/msgpack/msgpack-1.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/murmurhash/murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/numpy/numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/opencv_contrib_python/opencv_contrib_python-4.5.2.54-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pathy/pathy-0.6.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/platformdirs/platformdirs-2.5.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/preshed/preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pydantic/pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pyDeprecate/pyDeprecate-0.3.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pytorch_widedeep/pytorch_widedeep-1.1.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/ray/ray-1.12.0-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/smart_open/smart_open-5.2.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy/spacy-3.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy_legacy/spacy_legacy-3.0.9-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy_loggers/spacy_loggers-1.0.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/srsly/srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tensorboardX/tensorboardX-2.5-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/thinc/thinc-8.0.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/torchmetrics/torchmetrics-0.8.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/typer/typer-0.4.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/virtualenv/virtualenv-20.14.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/wasabi/wasabi-0.9.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/wrapt/wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_script_utilities/sagemaker_jumpstart_script_utilities-1.0.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from fastparquet==0.8.1->-r requirements.txt (line 8)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from fastparquet==0.8.1->-r requirements.txt (line 8)) (2021.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim==4.2.0->-r requirements.txt (line 11)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.8/site-packages (from grpcio==1.43.0->-r requirements.txt (line 12)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources==5.7.1->-r requirements.txt (line 13)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic==1.8.2->-r requirements.txt (line 23)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (1.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (4.62.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (5.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.15.3 in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (3.18.1)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema\u001b[0m\n",
      "\u001b[34mDownloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (58.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy==3.3.0->-r requirements.txt (line 28)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet==0.8.1->-r requirements.txt (line 8)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet==0.8.1->-r requirements.txt (line 8)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy==3.3.0->-r requirements.txt (line 28)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\u001b[0m\n",
      "\u001b[34mDownloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10\u001b[0m\n",
      "\u001b[34mDownloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (8.3.2)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: imutils\u001b[0m\n",
      "\u001b[34mBuilding wheel for imutils (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for imutils (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=271d17b158a35d2a43679f06cf6373d03cabbf289d19f92edeaf61f26ad058a6\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/fd/e4/e9/4c884662e099e733d692dbe899b279f593a41497be3c212c1d\u001b[0m\n",
      "\u001b[34mSuccessfully built imutils\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyrsistent, platformdirs, pkgutil-resolve-name, numpy, murmurhash, importlib-resources, frozenlist, filelock, distlib, cymem, catalogue, wasabi, virtualenv, typer, srsly, smart-open, pydantic, preshed, msgpack, jsonschema, grpcio, blis, aiosignal, thinc, tensorboardX, spacy-loggers, spacy-legacy, ray, pyDeprecate, pathy, langcodes, cramjam, wrapt, torchmetrics, spacy, opencv-contrib-python, imutils, gensim, fastparquet, einops, sagemaker-jumpstart-script-utilities, pytorch-widedeep\u001b[0m\n",
      "\u001b[34mAttempting uninstall: numpy\u001b[0m\n",
      "\u001b[34mFound existing installation: numpy 1.19.1\u001b[0m\n",
      "\u001b[34mUninstalling numpy-1.19.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled numpy-1.19.1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSuccessfully installed aiosignal-1.2.0 blis-0.7.7 catalogue-2.0.7 cramjam-2.5.0 cymem-2.0.6 distlib-0.3.4 einops-0.4.1 fastparquet-0.8.1 filelock-3.7.0 frozenlist-1.3.0 gensim-4.2.0 grpcio-1.43.0 importlib-resources-5.7.1 imutils-0.5.4 jsonschema-4.17.3 langcodes-3.3.0 msgpack-1.0.3 murmurhash-1.0.7 numpy-1.22.3 opencv-contrib-python-4.5.2.54 pathy-0.6.1 pkgutil-resolve-name-1.3.10 platformdirs-2.5.2 preshed-3.0.6 pyDeprecate-0.3.2 pydantic-1.8.2 pyrsistent-0.19.3 pytorch-widedeep-1.1.1 ray-1.12.0 sagemaker-jumpstart-script-utilities-1.0.1 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 tensorboardX-2.5 thinc-8.0.15 torchmetrics-0.8.2 typer-0.4.1 virtualenv-20.14.1 wasabi-0.9.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:33,623 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:33,634 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:33,644 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-04 07:04:33,652 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"attn_dropout\": 0.23174447846243657,\n",
      "        \"batch_size\": 128,\n",
      "        \"frac_shared_embed\": \"0.25\",\n",
      "        \"input_dim\": \"32\",\n",
      "        \"learning_rate\": 0.0015378552188176709,\n",
      "        \"mlp_dropout\": 0.530977533537545,\n",
      "        \"n_blocks\": \"4\",\n",
      "        \"n_epochs\": \"19\",\n",
      "        \"patience\": \"10\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"jumpstart-pytorch-tabtransformerclassif-2023-07-04-07-01-15-639\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"attn_dropout\":0.23174447846243657,\"batch_size\":128,\"frac_shared_embed\":\"0.25\",\"input_dim\":\"32\",\"learning_rate\":0.0015378552188176709,\"mlp_dropout\":0.530977533537545,\"n_blocks\":\"4\",\"n_epochs\":\"19\",\"patience\":\"10\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"attn_dropout\":0.23174447846243657,\"batch_size\":128,\"frac_shared_embed\":\"0.25\",\"input_dim\":\"32\",\"learning_rate\":0.0015378552188176709,\"mlp_dropout\":0.530977533537545,\"n_blocks\":\"4\",\"n_epochs\":\"19\",\"patience\":\"10\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"jumpstart-pytorch-tabtransformerclassif-2023-07-04-07-01-15-639\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--attn_dropout\",\"0.23174447846243657\",\"--batch_size\",\"128\",\"--frac_shared_embed\",\"0.25\",\"--input_dim\",\"32\",\"--learning_rate\",\"0.0015378552188176709\",\"--mlp_dropout\",\"0.530977533537545\",\"--n_blocks\",\"4\",\"--n_epochs\",\"19\",\"--patience\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ATTN_DROPOUT=0.23174447846243657\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_FRAC_SHARED_EMBED=0.25\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0015378552188176709\u001b[0m\n",
      "\u001b[34mSM_HP_MLP_DROPOUT=0.530977533537545\u001b[0m\n",
      "\u001b[34mSM_HP_N_BLOCKS=4\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS=19\u001b[0m\n",
      "\u001b[34mSM_HP_PATIENCE=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 transfer_learning.py --attn_dropout 0.23174447846243657 --batch_size 128 --frac_shared_embed 0.25 --input_dim 32 --learning_rate 0.0015378552188176709 --mlp_dropout 0.530977533537545 --n_blocks 4 --n_epochs 19 --patience 10\u001b[0m\n",
      "\u001b[34mINFO:root:Data in the validation channel is found. Reading the train and validation data from the training and validation channel, respectively.\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.162 algo-1:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug/core/tfevent/util.py:29: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\u001b[0m\n",
      "\u001b[34mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.dtype(np.bool): \"DT_BOOL\",\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.282 algo-1:48 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.282 algo-1:48 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.283 algo-1:48 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.283 algo-1:48 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.283 algo-1:48 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mepoch 1:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.393 algo-1:48 INFO hook.py:591] name:deeptabular.0.cat_and_cont_embed.cont_embed.weight count_params:1792\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.393 algo-1:48 INFO hook.py:591] name:deeptabular.0.cat_and_cont_embed.cont_embed.bias count_params:1792\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.393 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.394 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_0.0.weight count_params:12845056\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_0.0.bias count_params:7168\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_1.0.weight count_params:25690112\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_1.0.bias count_params:3584\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.1.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:591] name:deeptabular.1.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:593] Total Trainable Params: 38603393\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.395 algo-1:48 INFO hook.py:424] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-07-04 07:04:36.398 algo-1:48 INFO hook.py:488] Hook is writing from the hook with pid: 48\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug/core/tfevent/util.py:56: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  dtype=dtype, tensor_content=nparray_data.tostring(), tensor_shape=tps\u001b[0m\n",
      "\u001b[34mepoch 1:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.693, metrics={'f1': 0.4407}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:00<00:06,  1.16it/s, loss=0.693, metrics={'f1': 0.4407}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:00<00:06,  1.16it/s, loss=0.693, metrics={'f1': 0.4407}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:01<00:06,  1.16it/s, loss=4.68, metrics={'f1': 0.5987}]\u001b[0m\n",
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.68it/s, loss=4.68, metrics={'f1': 0.5987}]\u001b[0m\n",
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.68it/s, loss=4.68, metrics={'f1': 0.5987}]\u001b[0m\n",
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.68it/s, loss=10.5, metrics={'f1': 0.4909}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:01<00:02,  1.99it/s, loss=10.5, metrics={'f1': 0.4909}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:01<00:02,  1.99it/s, loss=10.5, metrics={'f1': 0.4909}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:02<00:02,  1.99it/s, loss=9.15, metrics={'f1': 0.4302}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.20it/s, loss=9.15, metrics={'f1': 0.4302}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.20it/s, loss=9.15, metrics={'f1': 0.4302}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.20it/s, loss=7.49, metrics={'f1': 0.3775}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=7.49, metrics={'f1': 0.3775}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=7.49, metrics={'f1': 0.3775}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=6.37, metrics={'f1': 0.4602}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:02<00:00,  2.47it/s, loss=6.37, metrics={'f1': 0.4602}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:02<00:00,  2.47it/s, loss=6.37, metrics={'f1': 0.4602}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:03<00:00,  2.47it/s, loss=5.54, metrics={'f1': 0.5301}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.52it/s, loss=5.54, metrics={'f1': 0.5301}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.52it/s, loss=5.54, metrics={'f1': 0.5301}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.52it/s, loss=4.98, metrics={'f1': 0.5356}]\u001b[0m\n",
      "\u001b[34mepoch 1: 100%|██████████| 8/8 [00:03<00:00,  2.93it/s, loss=4.98, metrics={'f1': 0.5356}]\u001b[0m\n",
      "\u001b[34mepoch 1: 100%|██████████| 8/8 [00:03<00:00,  2.36it/s, loss=4.98, metrics={'f1': 0.5356}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.744, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.744, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.744, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.762, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.762, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.762, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.757, metrics={'f1': 0.6983}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.80it/s, loss=0.757, metrics={'f1': 0.6983}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.80it/s, loss=0.757, metrics={'f1': 0.6983}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.80it/s, loss=0.807, metrics={'f1': 0.6736}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.80it/s, loss=0.807, metrics={'f1': 0.6736}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.80it/s, loss=0.818, metrics={'f1': 0.6681}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s, loss=0.818, metrics={'f1': 0.6681}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s, loss=0.818, metrics={'f1': 0.6681}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s, loss=0.82, metrics={'f1': 0.669}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s, loss=0.82, metrics={'f1': 0.669}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s, loss=0.802, metrics={'f1': 0.6833}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.22it/s, loss=0.802, metrics={'f1': 0.6833}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.22it/s, loss=0.802, metrics={'f1': 0.6833}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.22it/s, loss=0.803, metrics={'f1': 0.6823}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.44it/s, loss=0.803, metrics={'f1': 0.6823}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 2:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 2:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.705, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.705, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.705, metrics={'f1': 0.7005}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.681, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.681, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.681, metrics={'f1': 0.6972}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:02<00:04,  1.25it/s, loss=0.678, metrics={'f1': 0.7009}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.678, metrics={'f1': 0.7009}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.678, metrics={'f1': 0.7009}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.679, metrics={'f1': 0.6783}]\u001b[0m\n",
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:02<00:02,  1.69it/s, loss=0.679, metrics={'f1': 0.6783}]\u001b[0m\n",
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:02<00:02,  1.69it/s, loss=0.679, metrics={'f1': 0.6783}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:03<00:02,  1.69it/s, loss=0.675, metrics={'f1': 0.6778}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.675, metrics={'f1': 0.6778}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.675, metrics={'f1': 0.6778}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.668, metrics={'f1': 0.6822}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.05it/s, loss=0.668, metrics={'f1': 0.6822}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.05it/s, loss=0.668, metrics={'f1': 0.6822}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.05it/s, loss=0.661, metrics={'f1': 0.6864}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.661, metrics={'f1': 0.6864}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.661, metrics={'f1': 0.6864}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:04<00:00,  2.20it/s, loss=0.651, metrics={'f1': 0.6885}]\u001b[0m\n",
      "\u001b[34mepoch 2: 100%|██████████| 8/8 [00:04<00:00,  2.61it/s, loss=0.651, metrics={'f1': 0.6885}]\u001b[0m\n",
      "\u001b[34mepoch 2: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s, loss=0.651, metrics={'f1': 0.6885}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.449, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.449, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.449, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.461, metrics={'f1': 0.8435}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.26it/s, loss=0.461, metrics={'f1': 0.8435}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.26it/s, loss=0.461, metrics={'f1': 0.8435}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.26it/s, loss=0.461, metrics={'f1': 0.8408}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.26it/s, loss=0.461, metrics={'f1': 0.8408}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.26it/s, loss=0.5, metrics={'f1': 0.8078}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.86it/s, loss=0.5, metrics={'f1': 0.8078}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.86it/s, loss=0.5, metrics={'f1': 0.8078}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.86it/s, loss=0.505, metrics={'f1': 0.7974}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.86it/s, loss=0.505, metrics={'f1': 0.7974}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.86it/s, loss=0.509, metrics={'f1': 0.7944}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s, loss=0.509, metrics={'f1': 0.7944}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s, loss=0.509, metrics={'f1': 0.7944}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s, loss=0.511, metrics={'f1': 0.7985}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s, loss=0.511, metrics={'f1': 0.7985}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s, loss=0.503, metrics={'f1': 0.7975}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.82it/s, loss=0.503, metrics={'f1': 0.7975}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.19it/s, loss=0.503, metrics={'f1': 0.7975}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 3:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 3:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.514, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.39s/it, loss=0.514, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.39s/it, loss=0.514, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.39s/it, loss=0.501, metrics={'f1': 0.8041}]\u001b[0m\n",
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.501, metrics={'f1': 0.8041}]\u001b[0m\n",
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.501, metrics={'f1': 0.8041}]\u001b[0m\n",
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:02<00:04,  1.21it/s, loss=0.484, metrics={'f1': 0.7942}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.484, metrics={'f1': 0.7942}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.484, metrics={'f1': 0.7942}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.511, metrics={'f1': 0.7595}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:02<00:02,  1.75it/s, loss=0.511, metrics={'f1': 0.7595}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:02<00:02,  1.75it/s, loss=0.511, metrics={'f1': 0.7595}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:03<00:02,  1.75it/s, loss=0.497, metrics={'f1': 0.7622}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.497, metrics={'f1': 0.7622}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.497, metrics={'f1': 0.7622}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.491, metrics={'f1': 0.7668}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:03<00:01,  1.97it/s, loss=0.491, metrics={'f1': 0.7668}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:03<00:01,  1.97it/s, loss=0.491, metrics={'f1': 0.7668}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:04<00:01,  1.97it/s, loss=0.501, metrics={'f1': 0.766}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:04<00:00,  2.11it/s, loss=0.501, metrics={'f1': 0.766}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:04<00:00,  2.11it/s, loss=0.501, metrics={'f1': 0.766}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:04<00:00,  2.11it/s, loss=0.477, metrics={'f1': 0.7697}]\u001b[0m\n",
      "\u001b[34mepoch 3: 100%|██████████| 8/8 [00:04<00:00,  2.53it/s, loss=0.477, metrics={'f1': 0.7697}]\u001b[0m\n",
      "\u001b[34mepoch 3: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s, loss=0.477, metrics={'f1': 0.7697}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.291, metrics={'f1': 0.8682}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.291, metrics={'f1': 0.8682}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.291, metrics={'f1': 0.8682}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.276, metrics={'f1': 0.9037}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.276, metrics={'f1': 0.9037}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.276, metrics={'f1': 0.9037}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.275, metrics={'f1': 0.9002}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.275, metrics={'f1': 0.9002}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.341, metrics={'f1': 0.8593}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.31it/s, loss=0.341, metrics={'f1': 0.8593}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.31it/s, loss=0.341, metrics={'f1': 0.8593}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.31it/s, loss=0.353, metrics={'f1': 0.8525}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.31it/s, loss=0.353, metrics={'f1': 0.8525}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.31it/s, loss=0.371, metrics={'f1': 0.849}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.371, metrics={'f1': 0.849}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.371, metrics={'f1': 0.849}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.386, metrics={'f1': 0.8474}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.386, metrics={'f1': 0.8474}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.369, metrics={'f1': 0.848}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.63it/s, loss=0.369, metrics={'f1': 0.848}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.55it/s, loss=0.369, metrics={'f1': 0.848}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 4:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 4:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.378, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.378, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.378, metrics={'f1': 0.8571}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.379, metrics={'f1': 0.8165}]\u001b[0m\n",
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.379, metrics={'f1': 0.8165}]\u001b[0m\n",
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.379, metrics={'f1': 0.8165}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:02<00:04,  1.22it/s, loss=0.371, metrics={'f1': 0.8112}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.371, metrics={'f1': 0.8112}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.371, metrics={'f1': 0.8112}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.404, metrics={'f1': 0.7992}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.404, metrics={'f1': 0.7992}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.404, metrics={'f1': 0.7992}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:03<00:02,  1.72it/s, loss=0.415, metrics={'f1': 0.7917}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.415, metrics={'f1': 0.7917}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.415, metrics={'f1': 0.7917}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.419, metrics={'f1': 0.7914}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.419, metrics={'f1': 0.7914}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.419, metrics={'f1': 0.7914}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.442, metrics={'f1': 0.7842}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:03<00:00,  2.22it/s, loss=0.442, metrics={'f1': 0.7842}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:03<00:00,  2.22it/s, loss=0.442, metrics={'f1': 0.7842}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:04<00:00,  2.22it/s, loss=0.429, metrics={'f1': 0.7856}]\u001b[0m\n",
      "\u001b[34mepoch 4: 100%|██████████| 8/8 [00:04<00:00,  2.62it/s, loss=0.429, metrics={'f1': 0.7856}]\u001b[0m\n",
      "\u001b[34mepoch 4: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s, loss=0.429, metrics={'f1': 0.7856}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.242, metrics={'f1': 0.9444}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.50it/s, loss=0.242, metrics={'f1': 0.9444}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.50it/s, loss=0.242, metrics={'f1': 0.9444}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.50it/s, loss=0.241, metrics={'f1': 0.931}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.37it/s, loss=0.241, metrics={'f1': 0.931}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.37it/s, loss=0.241, metrics={'f1': 0.931}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.37it/s, loss=0.23, metrics={'f1': 0.9355}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.37it/s, loss=0.23, metrics={'f1': 0.9355}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.37it/s, loss=0.286, metrics={'f1': 0.9039}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.23it/s, loss=0.286, metrics={'f1': 0.9039}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.23it/s, loss=0.286, metrics={'f1': 0.9039}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.23it/s, loss=0.302, metrics={'f1': 0.8924}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.23it/s, loss=0.302, metrics={'f1': 0.8924}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.23it/s, loss=0.323, metrics={'f1': 0.8863}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.323, metrics={'f1': 0.8863}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.323, metrics={'f1': 0.8863}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.327, metrics={'f1': 0.8874}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.327, metrics={'f1': 0.8874}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.317, metrics={'f1': 0.8861}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.18it/s, loss=0.317, metrics={'f1': 0.8861}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.40it/s, loss=0.317, metrics={'f1': 0.8861}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 5:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 5:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.331, metrics={'f1': 0.8611}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.331, metrics={'f1': 0.8611}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.331, metrics={'f1': 0.8611}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.357, metrics={'f1': 0.8581}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.357, metrics={'f1': 0.8581}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.357, metrics={'f1': 0.8581}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:02<00:04,  1.25it/s, loss=0.329, metrics={'f1': 0.8776}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.329, metrics={'f1': 0.8776}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.329, metrics={'f1': 0.8776}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.343, metrics={'f1': 0.8672}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.343, metrics={'f1': 0.8672}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.343, metrics={'f1': 0.8672}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:03<00:02,  1.74it/s, loss=0.352, metrics={'f1': 0.8549}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.96it/s, loss=0.352, metrics={'f1': 0.8549}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.96it/s, loss=0.352, metrics={'f1': 0.8549}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.96it/s, loss=0.363, metrics={'f1': 0.8455}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.363, metrics={'f1': 0.8455}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.363, metrics={'f1': 0.8455}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.362, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:03<00:00,  2.30it/s, loss=0.362, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:03<00:00,  2.30it/s, loss=0.362, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:04<00:00,  2.30it/s, loss=0.343, metrics={'f1': 0.8562}]\u001b[0m\n",
      "\u001b[34mepoch 5: 100%|██████████| 8/8 [00:04<00:00,  2.72it/s, loss=0.343, metrics={'f1': 0.8562}]\u001b[0m\n",
      "\u001b[34mepoch 5: 100%|██████████| 8/8 [00:04<00:00,  1.97it/s, loss=0.343, metrics={'f1': 0.8562}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.212, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.212, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.212, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.205, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.49it/s, loss=0.205, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.49it/s, loss=0.205, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.49it/s, loss=0.196, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.49it/s, loss=0.196, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.49it/s, loss=0.247, metrics={'f1': 0.9203}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.40it/s, loss=0.247, metrics={'f1': 0.9203}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.40it/s, loss=0.247, metrics={'f1': 0.9203}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.40it/s, loss=0.264, metrics={'f1': 0.9096}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.40it/s, loss=0.264, metrics={'f1': 0.9096}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.40it/s, loss=0.283, metrics={'f1': 0.9012}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.35it/s, loss=0.283, metrics={'f1': 0.9012}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.35it/s, loss=0.283, metrics={'f1': 0.9012}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.35it/s, loss=0.286, metrics={'f1': 0.9045}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  8.67it/s, loss=0.286, metrics={'f1': 0.9045}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  8.67it/s, loss=0.286, metrics={'f1': 0.9045}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:01<00:00,  8.67it/s, loss=0.274, metrics={'f1': 0.9045}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00,  7.74it/s, loss=0.274, metrics={'f1': 0.9045}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 6:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 6:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.243, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:10,  1.46s/it, loss=0.243, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:10,  1.46s/it, loss=0.243, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:10,  1.46s/it, loss=0.275, metrics={'f1': 0.8997}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:01<00:05,  1.10it/s, loss=0.275, metrics={'f1': 0.8997}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:01<00:05,  1.10it/s, loss=0.275, metrics={'f1': 0.8997}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:02<00:05,  1.10it/s, loss=0.27, metrics={'f1': 0.9044}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.38it/s, loss=0.27, metrics={'f1': 0.9044}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.38it/s, loss=0.27, metrics={'f1': 0.9044}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.38it/s, loss=0.284, metrics={'f1': 0.8931}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:02<00:02,  1.61it/s, loss=0.284, metrics={'f1': 0.8931}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:02<00:02,  1.61it/s, loss=0.284, metrics={'f1': 0.8931}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:03<00:02,  1.61it/s, loss=0.298, metrics={'f1': 0.8781}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.77it/s, loss=0.298, metrics={'f1': 0.8781}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.77it/s, loss=0.298, metrics={'f1': 0.8781}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.77it/s, loss=0.31, metrics={'f1': 0.8717}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:03<00:00,  2.03it/s, loss=0.31, metrics={'f1': 0.8717}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:03<00:00,  2.03it/s, loss=0.31, metrics={'f1': 0.8717}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:04<00:00,  2.03it/s, loss=0.318, metrics={'f1': 0.8713}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:04<00:00,  2.19it/s, loss=0.318, metrics={'f1': 0.8713}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:04<00:00,  2.19it/s, loss=0.318, metrics={'f1': 0.8713}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:04<00:00,  2.19it/s, loss=0.308, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mepoch 6: 100%|██████████| 8/8 [00:04<00:00,  2.60it/s, loss=0.308, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mepoch 6: 100%|██████████| 8/8 [00:04<00:00,  1.83it/s, loss=0.308, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.192, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.192, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.192, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.156, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.156, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.156, metrics={'f1': 0.9714}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.154, metrics={'f1': 0.9693}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.85it/s, loss=0.154, metrics={'f1': 0.9693}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.85it/s, loss=0.154, metrics={'f1': 0.9693}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.85it/s, loss=0.201, metrics={'f1': 0.9505}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.90it/s, loss=0.201, metrics={'f1': 0.9505}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.90it/s, loss=0.201, metrics={'f1': 0.9505}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.90it/s, loss=0.221, metrics={'f1': 0.9381}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.90it/s, loss=0.221, metrics={'f1': 0.9381}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.90it/s, loss=0.241, metrics={'f1': 0.9306}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.61it/s, loss=0.241, metrics={'f1': 0.9306}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.61it/s, loss=0.241, metrics={'f1': 0.9306}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.61it/s, loss=0.248, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.61it/s, loss=0.248, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.61it/s, loss=0.234, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.77it/s, loss=0.234, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.29it/s, loss=0.234, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 7:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 7:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.22, metrics={'f1': 0.9065}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:08,  1.28s/it, loss=0.22, metrics={'f1': 0.9065}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:08,  1.28s/it, loss=0.22, metrics={'f1': 0.9065}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:08,  1.28s/it, loss=0.217, metrics={'f1': 0.9085}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:01<00:04,  1.34it/s, loss=0.217, metrics={'f1': 0.9085}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:01<00:04,  1.34it/s, loss=0.217, metrics={'f1': 0.9085}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:02<00:04,  1.34it/s, loss=0.214, metrics={'f1': 0.9209}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:02,  1.70it/s, loss=0.214, metrics={'f1': 0.9209}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:02,  1.70it/s, loss=0.214, metrics={'f1': 0.9209}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:02,  1.70it/s, loss=0.248, metrics={'f1': 0.9051}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:02<00:02,  1.95it/s, loss=0.248, metrics={'f1': 0.9051}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:02<00:02,  1.95it/s, loss=0.248, metrics={'f1': 0.9051}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:02<00:02,  1.95it/s, loss=0.256, metrics={'f1': 0.9006}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:02<00:01,  2.15it/s, loss=0.256, metrics={'f1': 0.9006}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:02<00:01,  2.15it/s, loss=0.256, metrics={'f1': 0.9006}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:03<00:01,  2.15it/s, loss=0.266, metrics={'f1': 0.8943}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.27it/s, loss=0.266, metrics={'f1': 0.8943}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.27it/s, loss=0.266, metrics={'f1': 0.8943}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.27it/s, loss=0.287, metrics={'f1': 0.8867}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:03<00:00,  2.40it/s, loss=0.287, metrics={'f1': 0.8867}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:03<00:00,  2.40it/s, loss=0.287, metrics={'f1': 0.8867}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:03<00:00,  2.40it/s, loss=0.271, metrics={'f1': 0.8889}]\u001b[0m\n",
      "\u001b[34mepoch 7: 100%|██████████| 8/8 [00:03<00:00,  2.81it/s, loss=0.271, metrics={'f1': 0.8889}]\u001b[0m\n",
      "\u001b[34mepoch 7: 100%|██████████| 8/8 [00:03<00:00,  2.10it/s, loss=0.271, metrics={'f1': 0.8889}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.175, metrics={'f1': 0.9565}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.66it/s, loss=0.175, metrics={'f1': 0.9565}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.66it/s, loss=0.175, metrics={'f1': 0.9565}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.66it/s, loss=0.138, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.138, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.138, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.131, metrics={'f1': 0.9642}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.131, metrics={'f1': 0.9642}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.161, metrics={'f1': 0.9533}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.80it/s, loss=0.161, metrics={'f1': 0.9533}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.80it/s, loss=0.161, metrics={'f1': 0.9533}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.80it/s, loss=0.176, metrics={'f1': 0.9444}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.80it/s, loss=0.176, metrics={'f1': 0.9444}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.80it/s, loss=0.188, metrics={'f1': 0.9403}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s, loss=0.188, metrics={'f1': 0.9403}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s, loss=0.188, metrics={'f1': 0.9403}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s, loss=0.195, metrics={'f1': 0.9411}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s, loss=0.195, metrics={'f1': 0.9411}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s, loss=0.181, metrics={'f1': 0.9427}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.25it/s, loss=0.181, metrics={'f1': 0.9427}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.45it/s, loss=0.181, metrics={'f1': 0.9427}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 8:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 8:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.212, metrics={'f1': 0.9323}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.212, metrics={'f1': 0.9323}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.212, metrics={'f1': 0.9323}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.235, metrics={'f1': 0.9053}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s, loss=0.235, metrics={'f1': 0.9053}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s, loss=0.235, metrics={'f1': 0.9053}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:02<00:04,  1.24it/s, loss=0.228, metrics={'f1': 0.9163}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.228, metrics={'f1': 0.9163}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.228, metrics={'f1': 0.9163}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.259, metrics={'f1': 0.8996}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:02<00:02,  1.84it/s, loss=0.259, metrics={'f1': 0.8996}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:02<00:02,  1.84it/s, loss=0.259, metrics={'f1': 0.8996}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:03<00:02,  1.84it/s, loss=0.256, metrics={'f1': 0.8944}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.256, metrics={'f1': 0.8944}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.256, metrics={'f1': 0.8944}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.259, metrics={'f1': 0.8917}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.11it/s, loss=0.259, metrics={'f1': 0.8917}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.11it/s, loss=0.259, metrics={'f1': 0.8917}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.11it/s, loss=0.275, metrics={'f1': 0.8844}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:03<00:00,  2.28it/s, loss=0.275, metrics={'f1': 0.8844}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:03<00:00,  2.28it/s, loss=0.275, metrics={'f1': 0.8844}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:04<00:00,  2.28it/s, loss=0.265, metrics={'f1': 0.8854}]\u001b[0m\n",
      "\u001b[34mepoch 8: 100%|██████████| 8/8 [00:04<00:00,  2.73it/s, loss=0.265, metrics={'f1': 0.8854}]\u001b[0m\n",
      "\u001b[34mepoch 8: 100%|██████████| 8/8 [00:04<00:00,  1.97it/s, loss=0.265, metrics={'f1': 0.8854}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.253, metrics={'f1': 0.8992}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.253, metrics={'f1': 0.8992}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.253, metrics={'f1': 0.8992}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.201, metrics={'f1': 0.9272}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.23it/s, loss=0.201, metrics={'f1': 0.9272}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.23it/s, loss=0.201, metrics={'f1': 0.9272}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.23it/s, loss=0.176, metrics={'f1': 0.9343}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s, loss=0.176, metrics={'f1': 0.9343}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s, loss=0.176, metrics={'f1': 0.9343}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s, loss=0.178, metrics={'f1': 0.928}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s, loss=0.178, metrics={'f1': 0.928}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s, loss=0.183, metrics={'f1': 0.9288}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.87it/s, loss=0.183, metrics={'f1': 0.9288}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.87it/s, loss=0.183, metrics={'f1': 0.9288}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.87it/s, loss=0.183, metrics={'f1': 0.9303}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.87it/s, loss=0.183, metrics={'f1': 0.9303}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.87it/s, loss=0.192, metrics={'f1': 0.9321}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.99it/s, loss=0.192, metrics={'f1': 0.9321}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.99it/s, loss=0.192, metrics={'f1': 0.9321}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.99it/s, loss=0.181, metrics={'f1': 0.9319}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.14it/s, loss=0.181, metrics={'f1': 0.9319}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 9:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 9:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.255, metrics={'f1': 0.8819}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.255, metrics={'f1': 0.8819}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.255, metrics={'f1': 0.8819}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.227, metrics={'f1': 0.9084}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:01<00:04,  1.26it/s, loss=0.227, metrics={'f1': 0.9084}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:01<00:04,  1.26it/s, loss=0.227, metrics={'f1': 0.9084}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:02<00:04,  1.26it/s, loss=0.215, metrics={'f1': 0.9212}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.215, metrics={'f1': 0.9212}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.215, metrics={'f1': 0.9212}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.274, metrics={'f1': 0.8976}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.274, metrics={'f1': 0.8976}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.274, metrics={'f1': 0.8976}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:03<00:02,  1.78it/s, loss=0.278, metrics={'f1': 0.8915}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.278, metrics={'f1': 0.8915}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.278, metrics={'f1': 0.8915}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.27, metrics={'f1': 0.8938}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.27, metrics={'f1': 0.8938}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.27, metrics={'f1': 0.8938}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.273, metrics={'f1': 0.8954}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.273, metrics={'f1': 0.8954}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.273, metrics={'f1': 0.8954}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.27, metrics={'f1': 0.8961}]\u001b[0m\n",
      "\u001b[34mepoch 9: 100%|██████████| 8/8 [00:04<00:00,  2.67it/s, loss=0.27, metrics={'f1': 0.8961}]\u001b[0m\n",
      "\u001b[34mepoch 9: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s, loss=0.27, metrics={'f1': 0.8961}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.392, metrics={'f1': 0.8235}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.392, metrics={'f1': 0.8235}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.392, metrics={'f1': 0.8235}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.54it/s, loss=0.344, metrics={'f1': 0.8452}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.16it/s, loss=0.344, metrics={'f1': 0.8452}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.16it/s, loss=0.344, metrics={'f1': 0.8452}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.16it/s, loss=0.302, metrics={'f1': 0.8641}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.16it/s, loss=0.302, metrics={'f1': 0.8641}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.16it/s, loss=0.289, metrics={'f1': 0.8627}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.83it/s, loss=0.289, metrics={'f1': 0.8627}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.83it/s, loss=0.289, metrics={'f1': 0.8627}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.83it/s, loss=0.287, metrics={'f1': 0.8626}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.83it/s, loss=0.287, metrics={'f1': 0.8626}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.83it/s, loss=0.277, metrics={'f1': 0.873}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.20it/s, loss=0.277, metrics={'f1': 0.873}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.20it/s, loss=0.277, metrics={'f1': 0.873}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.20it/s, loss=0.291, metrics={'f1': 0.8694}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.20it/s, loss=0.291, metrics={'f1': 0.8694}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.20it/s, loss=0.275, metrics={'f1': 0.871}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.40it/s, loss=0.275, metrics={'f1': 0.871}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.38it/s, loss=0.275, metrics={'f1': 0.871}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 10:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 10:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.354, metrics={'f1': 0.8264}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.354, metrics={'f1': 0.8264}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.354, metrics={'f1': 0.8264}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.271, metrics={'f1': 0.8924}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.271, metrics={'f1': 0.8924}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.271, metrics={'f1': 0.8924}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:02<00:04,  1.25it/s, loss=0.233, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.233, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.233, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.232, metrics={'f1': 0.916}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:02<00:02,  1.77it/s, loss=0.232, metrics={'f1': 0.916}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:02<00:02,  1.77it/s, loss=0.232, metrics={'f1': 0.916}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:03<00:02,  1.77it/s, loss=0.233, metrics={'f1': 0.9146}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.84it/s, loss=0.233, metrics={'f1': 0.9146}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.84it/s, loss=0.233, metrics={'f1': 0.9146}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.84it/s, loss=0.24, metrics={'f1': 0.9119}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:03<00:01,  1.96it/s, loss=0.24, metrics={'f1': 0.9119}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:03<00:01,  1.96it/s, loss=0.24, metrics={'f1': 0.9119}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:04<00:01,  1.96it/s, loss=0.242, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.242, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.242, metrics={'f1': 0.9147}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.226, metrics={'f1': 0.9162}]\u001b[0m\n",
      "\u001b[34mepoch 10: 100%|██████████| 8/8 [00:04<00:00,  2.56it/s, loss=0.226, metrics={'f1': 0.9162}]\u001b[0m\n",
      "\u001b[34mepoch 10: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s, loss=0.226, metrics={'f1': 0.9162}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.145, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.45it/s, loss=0.145, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.45it/s, loss=0.145, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.45it/s, loss=0.118, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.08it/s, loss=0.118, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.08it/s, loss=0.118, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.08it/s, loss=0.104, metrics={'f1': 0.961}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.50it/s, loss=0.104, metrics={'f1': 0.961}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.50it/s, loss=0.104, metrics={'f1': 0.961}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.50it/s, loss=0.114, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.68it/s, loss=0.114, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.68it/s, loss=0.114, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.68it/s, loss=0.123, metrics={'f1': 0.9518}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.68it/s, loss=0.123, metrics={'f1': 0.9518}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.68it/s, loss=0.127, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.48it/s, loss=0.127, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.48it/s, loss=0.127, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.48it/s, loss=0.133, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.48it/s, loss=0.133, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.48it/s, loss=0.124, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.76it/s, loss=0.124, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.04it/s, loss=0.124, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 11:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 11:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.181, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.181, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.181, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.183, metrics={'f1': 0.9208}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.183, metrics={'f1': 0.9208}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.183, metrics={'f1': 0.9208}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:02<00:04,  1.25it/s, loss=0.161, metrics={'f1': 0.9327}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.161, metrics={'f1': 0.9327}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.161, metrics={'f1': 0.9327}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.175, metrics={'f1': 0.9297}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:02<00:02,  1.70it/s, loss=0.175, metrics={'f1': 0.9297}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:02<00:02,  1.70it/s, loss=0.175, metrics={'f1': 0.9297}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:03<00:02,  1.70it/s, loss=0.182, metrics={'f1': 0.9255}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.182, metrics={'f1': 0.9255}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.182, metrics={'f1': 0.9255}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.182, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.182, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.182, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.14it/s, loss=0.186, metrics={'f1': 0.9241}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:03<00:00,  2.25it/s, loss=0.186, metrics={'f1': 0.9241}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:03<00:00,  2.25it/s, loss=0.186, metrics={'f1': 0.9241}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:04<00:00,  2.25it/s, loss=0.175, metrics={'f1': 0.9252}]\u001b[0m\n",
      "\u001b[34mepoch 11: 100%|██████████| 8/8 [00:04<00:00,  2.67it/s, loss=0.175, metrics={'f1': 0.9252}]\u001b[0m\n",
      "\u001b[34mepoch 11: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s, loss=0.175, metrics={'f1': 0.9252}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.133, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.133, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.133, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.63it/s, loss=0.1, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.40it/s, loss=0.1, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.40it/s, loss=0.1, metrics={'f1': 0.9517}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.40it/s, loss=0.0887, metrics={'f1': 0.961}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.40it/s, loss=0.0887, metrics={'f1': 0.961}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.40it/s, loss=0.0997, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.45it/s, loss=0.0997, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.45it/s, loss=0.0997, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.45it/s, loss=0.111, metrics={'f1': 0.9533}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.45it/s, loss=0.111, metrics={'f1': 0.9533}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.45it/s, loss=0.116, metrics={'f1': 0.9548}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.72it/s, loss=0.116, metrics={'f1': 0.9548}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.72it/s, loss=0.116, metrics={'f1': 0.9548}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.72it/s, loss=0.123, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.72it/s, loss=0.123, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.72it/s, loss=0.111, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.54it/s, loss=0.111, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.70it/s, loss=0.111, metrics={'f1': 0.9584}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 12:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 12:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.187, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.187, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.187, metrics={'f1': 0.9104}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.153, metrics={'f1': 0.9299}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:01<00:05,  1.18it/s, loss=0.153, metrics={'f1': 0.9299}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:01<00:05,  1.18it/s, loss=0.153, metrics={'f1': 0.9299}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:02<00:05,  1.18it/s, loss=0.134, metrics={'f1': 0.9443}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.134, metrics={'f1': 0.9443}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.134, metrics={'f1': 0.9443}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.50it/s, loss=0.145, metrics={'f1': 0.9376}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.145, metrics={'f1': 0.9376}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.145, metrics={'f1': 0.9376}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:03<00:02,  1.74it/s, loss=0.166, metrics={'f1': 0.9368}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.166, metrics={'f1': 0.9368}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.166, metrics={'f1': 0.9368}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.165, metrics={'f1': 0.9397}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.165, metrics={'f1': 0.9397}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.165, metrics={'f1': 0.9397}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.176, metrics={'f1': 0.9389}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.176, metrics={'f1': 0.9389}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.176, metrics={'f1': 0.9389}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.161, metrics={'f1': 0.9396}]\u001b[0m\n",
      "\u001b[34mepoch 12: 100%|██████████| 8/8 [00:04<00:00,  2.66it/s, loss=0.161, metrics={'f1': 0.9396}]\u001b[0m\n",
      "\u001b[34mepoch 12: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s, loss=0.161, metrics={'f1': 0.9396}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.112, metrics={'f1': 0.9784}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.112, metrics={'f1': 0.9784}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.112, metrics={'f1': 0.9784}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.0794, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.27it/s, loss=0.0794, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.27it/s, loss=0.0794, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.27it/s, loss=0.0704, metrics={'f1': 0.9856}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.27it/s, loss=0.0704, metrics={'f1': 0.9856}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.27it/s, loss=0.0787, metrics={'f1': 0.9829}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.39it/s, loss=0.0787, metrics={'f1': 0.9829}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.39it/s, loss=0.0787, metrics={'f1': 0.9829}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.39it/s, loss=0.0919, metrics={'f1': 0.98}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.39it/s, loss=0.0919, metrics={'f1': 0.98}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.39it/s, loss=0.0967, metrics={'f1': 0.9757}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.71it/s, loss=0.0967, metrics={'f1': 0.9757}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.71it/s, loss=0.0967, metrics={'f1': 0.9757}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.71it/s, loss=0.104, metrics={'f1': 0.9756}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.71it/s, loss=0.104, metrics={'f1': 0.9756}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.71it/s, loss=0.0922, metrics={'f1': 0.9763}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.63it/s, loss=0.0922, metrics={'f1': 0.9763}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.63it/s, loss=0.0922, metrics={'f1': 0.9763}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 13:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 13:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.131, metrics={'f1': 0.9635}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.131, metrics={'f1': 0.9635}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.131, metrics={'f1': 0.9635}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.127, metrics={'f1': 0.96}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.127, metrics={'f1': 0.96}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.127, metrics={'f1': 0.96}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:02<00:04,  1.22it/s, loss=0.131, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.131, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.131, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.14, metrics={'f1': 0.9456}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:02<00:02,  1.76it/s, loss=0.14, metrics={'f1': 0.9456}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:02<00:02,  1.76it/s, loss=0.14, metrics={'f1': 0.9456}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:03<00:02,  1.76it/s, loss=0.164, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.164, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.164, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.165, metrics={'f1': 0.9301}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.165, metrics={'f1': 0.9301}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.165, metrics={'f1': 0.9301}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.01it/s, loss=0.168, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:03<00:00,  2.12it/s, loss=0.168, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:03<00:00,  2.12it/s, loss=0.168, metrics={'f1': 0.9329}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:04<00:00,  2.12it/s, loss=0.152, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34mepoch 13: 100%|██████████| 8/8 [00:04<00:00,  2.49it/s, loss=0.152, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34mepoch 13: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s, loss=0.152, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.165, metrics={'f1': 0.9313}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.165, metrics={'f1': 0.9313}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.165, metrics={'f1': 0.9313}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.126, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.126, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.126, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.13it/s, loss=0.0983, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s, loss=0.0983, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s, loss=0.0983, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s, loss=0.0948, metrics={'f1': 0.9565}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s, loss=0.0948, metrics={'f1': 0.9565}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s, loss=0.102, metrics={'f1': 0.9553}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.60it/s, loss=0.102, metrics={'f1': 0.9553}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.60it/s, loss=0.102, metrics={'f1': 0.9553}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.60it/s, loss=0.0999, metrics={'f1': 0.9603}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.60it/s, loss=0.0999, metrics={'f1': 0.9603}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.60it/s, loss=0.107, metrics={'f1': 0.9593}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.62it/s, loss=0.107, metrics={'f1': 0.9593}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.62it/s, loss=0.107, metrics={'f1': 0.9593}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.62it/s, loss=0.0961, metrics={'f1': 0.9605}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.33it/s, loss=0.0961, metrics={'f1': 0.9605}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 14:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 14:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.162, metrics={'f1': 0.9242}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.162, metrics={'f1': 0.9242}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.162, metrics={'f1': 0.9242}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.132, metrics={'f1': 0.943}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.132, metrics={'f1': 0.943}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.132, metrics={'f1': 0.943}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:02<00:04,  1.23it/s, loss=0.118, metrics={'f1': 0.9531}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.118, metrics={'f1': 0.9531}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.118, metrics={'f1': 0.9531}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.143, metrics={'f1': 0.9446}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.143, metrics={'f1': 0.9446}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.143, metrics={'f1': 0.9446}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:03<00:02,  1.78it/s, loss=0.165, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.165, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.165, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.87it/s, loss=0.167, metrics={'f1': 0.9352}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.167, metrics={'f1': 0.9352}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.167, metrics={'f1': 0.9352}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.168, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.168, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:03<00:00,  2.26it/s, loss=0.168, metrics={'f1': 0.9349}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.159, metrics={'f1': 0.9357}]\u001b[0m\n",
      "\u001b[34mepoch 14: 100%|██████████| 8/8 [00:04<00:00,  2.68it/s, loss=0.159, metrics={'f1': 0.9357}]\u001b[0m\n",
      "\u001b[34mepoch 14: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s, loss=0.159, metrics={'f1': 0.9357}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.126, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.62it/s, loss=0.126, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.62it/s, loss=0.126, metrics={'f1': 0.9481}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.62it/s, loss=0.104, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.104, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.104, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.0853, metrics={'f1': 0.9704}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.0853, metrics={'f1': 0.9704}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.43it/s, loss=0.0845, metrics={'f1': 0.9648}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.51it/s, loss=0.0845, metrics={'f1': 0.9648}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.51it/s, loss=0.0845, metrics={'f1': 0.9648}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.51it/s, loss=0.0913, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.51it/s, loss=0.0913, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.51it/s, loss=0.0893, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.0893, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.0893, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.0945, metrics={'f1': 0.9651}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.0945, metrics={'f1': 0.9651}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.55it/s, loss=0.0861, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.66it/s, loss=0.0861, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.74it/s, loss=0.0861, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 15:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 15:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.174, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.174, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.174, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.138, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.138, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.138, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:02<00:04,  1.22it/s, loss=0.12, metrics={'f1': 0.9728}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.12, metrics={'f1': 0.9728}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.12, metrics={'f1': 0.9728}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.128, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:02<00:02,  1.80it/s, loss=0.128, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:02<00:02,  1.80it/s, loss=0.128, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:03<00:02,  1.80it/s, loss=0.14, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.14, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.14, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.144, metrics={'f1': 0.9514}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.144, metrics={'f1': 0.9514}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.144, metrics={'f1': 0.9514}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.12it/s, loss=0.147, metrics={'f1': 0.952}]\u001b[0m\n",
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.147, metrics={'f1': 0.952}]\u001b[0m\n",
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.147, metrics={'f1': 0.952}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:04<00:00,  2.20it/s, loss=0.138, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 15: 100%|██████████| 8/8 [00:04<00:00,  2.62it/s, loss=0.138, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 15: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s, loss=0.138, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.117, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.41it/s, loss=0.117, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.41it/s, loss=0.117, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.41it/s, loss=0.0966, metrics={'f1': 0.9466}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.97it/s, loss=0.0966, metrics={'f1': 0.9466}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.97it/s, loss=0.0966, metrics={'f1': 0.9466}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.97it/s, loss=0.0796, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.44it/s, loss=0.0796, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.44it/s, loss=0.0796, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.44it/s, loss=0.0818, metrics={'f1': 0.9562}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.44it/s, loss=0.0818, metrics={'f1': 0.9562}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.44it/s, loss=0.0895, metrics={'f1': 0.9547}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s, loss=0.0895, metrics={'f1': 0.9547}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s, loss=0.0895, metrics={'f1': 0.9547}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s, loss=0.0884, metrics={'f1': 0.9557}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s, loss=0.0884, metrics={'f1': 0.9557}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s, loss=0.0924, metrics={'f1': 0.9589}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.46it/s, loss=0.0924, metrics={'f1': 0.9589}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.46it/s, loss=0.0924, metrics={'f1': 0.9589}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.46it/s, loss=0.0844, metrics={'f1': 0.9602}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.20it/s, loss=0.0844, metrics={'f1': 0.9602}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 16:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 16:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.168, metrics={'f1': 0.9077}]\u001b[0m\n",
      "\u001b[34mepoch 16:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.168, metrics={'f1': 0.9077}]\u001b[0m\n",
      "\u001b[34mepoch 16:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.168, metrics={'f1': 0.9077}]\u001b[0m\n",
      "\u001b[34mepoch 16:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.183, metrics={'f1': 0.902}]\u001b[0m\n",
      "\u001b[34mepoch 16:  25%|██▌       | 2/8 [00:01<00:04,  1.20it/s, loss=0.183, metrics={'f1': 0.902}]\u001b[0m\n",
      "\u001b[34mepoch 16:  25%|██▌       | 2/8 [00:01<00:04,  1.20it/s, loss=0.183, metrics={'f1': 0.902}]\u001b[0m\n",
      "\u001b[34mepoch 16:  25%|██▌       | 2/8 [00:02<00:04,  1.20it/s, loss=0.156, metrics={'f1': 0.9211}]\u001b[0m\n",
      "\u001b[34mepoch 16:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.156, metrics={'f1': 0.9211}]\u001b[0m\n",
      "\u001b[34mepoch 16:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.156, metrics={'f1': 0.9211}]\u001b[0m\n",
      "\u001b[34mepoch 16:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.148, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 16:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.148, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 16:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.148, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 16:  50%|█████     | 4/8 [00:03<00:02,  1.72it/s, loss=0.149, metrics={'f1': 0.9314}]\u001b[0m\n",
      "\u001b[34mepoch 16:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.149, metrics={'f1': 0.9314}]\u001b[0m\n",
      "\u001b[34mepoch 16:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.149, metrics={'f1': 0.9314}]\u001b[0m\n",
      "\u001b[34mepoch 16:  62%|██████▎   | 5/8 [00:03<00:01,  1.94it/s, loss=0.147, metrics={'f1': 0.9344}]\u001b[0m\n",
      "\u001b[34mepoch 16:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.147, metrics={'f1': 0.9344}]\u001b[0m\n",
      "\u001b[34mepoch 16:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.147, metrics={'f1': 0.9344}]\u001b[0m\n",
      "\u001b[34mepoch 16:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.151, metrics={'f1': 0.9361}]\u001b[0m\n",
      "\u001b[34mepoch 16:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.151, metrics={'f1': 0.9361}]\u001b[0m\n",
      "\u001b[34mepoch 16:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.151, metrics={'f1': 0.9361}]\u001b[0m\n",
      "\u001b[34mepoch 16:  88%|████████▊ | 7/8 [00:04<00:00,  2.20it/s, loss=0.138, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34mepoch 16: 100%|██████████| 8/8 [00:04<00:00,  2.62it/s, loss=0.138, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34mepoch 16: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s, loss=0.138, metrics={'f1': 0.937}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0591, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.57it/s, loss=0.0591, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.57it/s, loss=0.0591, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.57it/s, loss=0.045, metrics={'f1': 0.9891}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.21it/s, loss=0.045, metrics={'f1': 0.9891}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.21it/s, loss=0.045, metrics={'f1': 0.9891}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.21it/s, loss=0.0388, metrics={'f1': 0.9903}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.32it/s, loss=0.0388, metrics={'f1': 0.9903}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.32it/s, loss=0.0388, metrics={'f1': 0.9903}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.32it/s, loss=0.0404, metrics={'f1': 0.9885}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.32it/s, loss=0.0404, metrics={'f1': 0.9885}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.32it/s, loss=0.0477, metrics={'f1': 0.9845}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.94it/s, loss=0.0477, metrics={'f1': 0.9845}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.94it/s, loss=0.0477, metrics={'f1': 0.9845}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.94it/s, loss=0.0479, metrics={'f1': 0.9845}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.94it/s, loss=0.0479, metrics={'f1': 0.9845}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.94it/s, loss=0.0512, metrics={'f1': 0.9839}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0512, metrics={'f1': 0.9839}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0512, metrics={'f1': 0.9839}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0462, metrics={'f1': 0.9844}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.11it/s, loss=0.0462, metrics={'f1': 0.9844}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 17:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 17:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.102, metrics={'f1': 0.9559}]\u001b[0m\n",
      "\u001b[34mepoch 17:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.102, metrics={'f1': 0.9559}]\u001b[0m\n",
      "\u001b[34mepoch 17:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.102, metrics={'f1': 0.9559}]\u001b[0m\n",
      "\u001b[34mepoch 17:  12%|█▎        | 1/8 [00:01<00:09,  1.34s/it, loss=0.101, metrics={'f1': 0.9632}]\u001b[0m\n",
      "\u001b[34mepoch 17:  25%|██▌       | 2/8 [00:01<00:04,  1.20it/s, loss=0.101, metrics={'f1': 0.9632}]\u001b[0m\n",
      "\u001b[34mepoch 17:  25%|██▌       | 2/8 [00:01<00:04,  1.20it/s, loss=0.101, metrics={'f1': 0.9632}]\u001b[0m\n",
      "\u001b[34mepoch 17:  25%|██▌       | 2/8 [00:02<00:04,  1.20it/s, loss=0.1, metrics={'f1': 0.9682}]\u001b[0m\n",
      "\u001b[34mepoch 17:  38%|███▊      | 3/8 [00:02<00:03,  1.41it/s, loss=0.1, metrics={'f1': 0.9682}]\u001b[0m\n",
      "\u001b[34mepoch 17:  38%|███▊      | 3/8 [00:02<00:03,  1.41it/s, loss=0.1, metrics={'f1': 0.9682}]\u001b[0m\n",
      "\u001b[34mepoch 17:  38%|███▊      | 3/8 [00:02<00:03,  1.41it/s, loss=0.108, metrics={'f1': 0.9653}]\u001b[0m\n",
      "\u001b[34mepoch 17:  50%|█████     | 4/8 [00:02<00:02,  1.55it/s, loss=0.108, metrics={'f1': 0.9653}]\u001b[0m\n",
      "\u001b[34mepoch 17:  50%|█████     | 4/8 [00:02<00:02,  1.55it/s, loss=0.108, metrics={'f1': 0.9653}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 17:  50%|█████     | 4/8 [00:03<00:02,  1.55it/s, loss=0.106, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  62%|██████▎   | 5/8 [00:03<00:01,  1.58it/s, loss=0.106, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  62%|██████▎   | 5/8 [00:03<00:01,  1.58it/s, loss=0.106, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  62%|██████▎   | 5/8 [00:04<00:01,  1.58it/s, loss=0.104, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  75%|███████▌  | 6/8 [00:04<00:01,  1.72it/s, loss=0.104, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  75%|███████▌  | 6/8 [00:04<00:01,  1.72it/s, loss=0.104, metrics={'f1': 0.9608}]\u001b[0m\n",
      "\u001b[34mepoch 17:  75%|███████▌  | 6/8 [00:04<00:01,  1.72it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34mepoch 17:  88%|████████▊ | 7/8 [00:04<00:00,  1.92it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34mepoch 17:  88%|████████▊ | 7/8 [00:04<00:00,  1.92it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34mepoch 17:  88%|████████▊ | 7/8 [00:04<00:00,  1.92it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34mepoch 17: 100%|██████████| 8/8 [00:04<00:00,  2.33it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34mepoch 17: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s, loss=0.103, metrics={'f1': 0.9621}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0451, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.51it/s, loss=0.0451, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.51it/s, loss=0.0451, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.51it/s, loss=0.0414, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.18it/s, loss=0.0414, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.18it/s, loss=0.0414, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.18it/s, loss=0.0363, metrics={'f1': 0.9856}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.25it/s, loss=0.0363, metrics={'f1': 0.9856}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.25it/s, loss=0.0363, metrics={'f1': 0.9856}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.25it/s, loss=0.0456, metrics={'f1': 0.9811}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.25it/s, loss=0.0456, metrics={'f1': 0.9811}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.25it/s, loss=0.0484, metrics={'f1': 0.9785}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.31it/s, loss=0.0484, metrics={'f1': 0.9785}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.31it/s, loss=0.0484, metrics={'f1': 0.9785}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.31it/s, loss=0.0471, metrics={'f1': 0.9795}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.31it/s, loss=0.0471, metrics={'f1': 0.9795}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.31it/s, loss=0.0472, metrics={'f1': 0.9787}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.33it/s, loss=0.0472, metrics={'f1': 0.9787}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.33it/s, loss=0.0472, metrics={'f1': 0.9787}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.33it/s, loss=0.0422, metrics={'f1': 0.9793}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.15it/s, loss=0.0422, metrics={'f1': 0.9793}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 18:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 18:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.0659, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mepoch 18:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.0659, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mepoch 18:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.0659, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mepoch 18:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.0912, metrics={'f1': 0.9749}]\u001b[0m\n",
      "\u001b[34mepoch 18:  25%|██▌       | 2/8 [00:01<00:05,  1.20it/s, loss=0.0912, metrics={'f1': 0.9749}]\u001b[0m\n",
      "\u001b[34mepoch 18:  25%|██▌       | 2/8 [00:01<00:05,  1.20it/s, loss=0.0912, metrics={'f1': 0.9749}]\u001b[0m\n",
      "\u001b[34mepoch 18:  25%|██▌       | 2/8 [00:02<00:05,  1.20it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 18:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 18:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 18:  38%|███▊      | 3/8 [00:02<00:03,  1.53it/s, loss=0.121, metrics={'f1': 0.959}]\u001b[0m\n",
      "\u001b[34mepoch 18:  50%|█████     | 4/8 [00:02<00:02,  1.69it/s, loss=0.121, metrics={'f1': 0.959}]\u001b[0m\n",
      "\u001b[34mepoch 18:  50%|█████     | 4/8 [00:02<00:02,  1.69it/s, loss=0.121, metrics={'f1': 0.959}]\u001b[0m\n",
      "\u001b[34mepoch 18:  50%|█████     | 4/8 [00:03<00:02,  1.69it/s, loss=0.116, metrics={'f1': 0.9588}]\u001b[0m\n",
      "\u001b[34mepoch 18:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.116, metrics={'f1': 0.9588}]\u001b[0m\n",
      "\u001b[34mepoch 18:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.116, metrics={'f1': 0.9588}]\u001b[0m\n",
      "\u001b[34mepoch 18:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.115, metrics={'f1': 0.9592}]\u001b[0m\n",
      "\u001b[34mepoch 18:  75%|███████▌  | 6/8 [00:03<00:00,  2.08it/s, loss=0.115, metrics={'f1': 0.9592}]\u001b[0m\n",
      "\u001b[34mepoch 18:  75%|███████▌  | 6/8 [00:03<00:00,  2.08it/s, loss=0.115, metrics={'f1': 0.9592}]\u001b[0m\n",
      "\u001b[34mepoch 18:  75%|███████▌  | 6/8 [00:03<00:00,  2.08it/s, loss=0.114, metrics={'f1': 0.9606}]\u001b[0m\n",
      "\u001b[34mepoch 18:  88%|████████▊ | 7/8 [00:03<00:00,  2.22it/s, loss=0.114, metrics={'f1': 0.9606}]\u001b[0m\n",
      "\u001b[34mepoch 18:  88%|████████▊ | 7/8 [00:03<00:00,  2.22it/s, loss=0.114, metrics={'f1': 0.9606}]\u001b[0m\n",
      "\u001b[34mepoch 18:  88%|████████▊ | 7/8 [00:04<00:00,  2.22it/s, loss=0.103, metrics={'f1': 0.9617}]\u001b[0m\n",
      "\u001b[34mepoch 18: 100%|██████████| 8/8 [00:04<00:00,  2.64it/s, loss=0.103, metrics={'f1': 0.9617}]\u001b[0m\n",
      "\u001b[34mepoch 18: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s, loss=0.103, metrics={'f1': 0.9617}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.071, metrics={'f1': 0.9778}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.071, metrics={'f1': 0.9778}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.071, metrics={'f1': 0.9778}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.48it/s, loss=0.0683, metrics={'f1': 0.9738}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.45it/s, loss=0.0683, metrics={'f1': 0.9738}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.45it/s, loss=0.0683, metrics={'f1': 0.9738}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.45it/s, loss=0.0576, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.68it/s, loss=0.0576, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.68it/s, loss=0.0576, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.68it/s, loss=0.0524, metrics={'f1': 0.9784}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.68it/s, loss=0.0524, metrics={'f1': 0.9784}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.68it/s, loss=0.058, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.98it/s, loss=0.058, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.98it/s, loss=0.058, metrics={'f1': 0.9777}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.98it/s, loss=0.0554, metrics={'f1': 0.9802}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.98it/s, loss=0.0554, metrics={'f1': 0.9802}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.98it/s, loss=0.0593, metrics={'f1': 0.9803}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0593, metrics={'f1': 0.9803}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0593, metrics={'f1': 0.9803}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.14it/s, loss=0.0538, metrics={'f1': 0.9809}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.20it/s, loss=0.0538, metrics={'f1': 0.9809}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 19:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 19:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.151, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 19:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.151, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 19:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.151, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 19:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.115, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mepoch 19:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s, loss=0.115, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mepoch 19:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s, loss=0.115, metrics={'f1': 0.9624}]\u001b[0m\n",
      "\u001b[34mepoch 19:  25%|██▌       | 2/8 [00:02<00:04,  1.24it/s, loss=0.102, metrics={'f1': 0.9681}]\u001b[0m\n",
      "\u001b[34mepoch 19:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.102, metrics={'f1': 0.9681}]\u001b[0m\n",
      "\u001b[34mepoch 19:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.102, metrics={'f1': 0.9681}]\u001b[0m\n",
      "\u001b[34mepoch 19:  38%|███▊      | 3/8 [00:02<00:03,  1.54it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 19:  50%|█████     | 4/8 [00:02<00:02,  1.84it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 19:  50%|█████     | 4/8 [00:02<00:02,  1.84it/s, loss=0.0958, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mepoch 19:  50%|█████     | 4/8 [00:03<00:02,  1.84it/s, loss=0.11, metrics={'f1': 0.9642}]\u001b[0m\n",
      "\u001b[34mepoch 19:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.11, metrics={'f1': 0.9642}]\u001b[0m\n",
      "\u001b[34mepoch 19:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.11, metrics={'f1': 0.9642}]\u001b[0m\n",
      "\u001b[34mepoch 19:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.109, metrics={'f1': 0.9652}]\u001b[0m\n",
      "\u001b[34mepoch 19:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.109, metrics={'f1': 0.9652}]\u001b[0m\n",
      "\u001b[34mepoch 19:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.109, metrics={'f1': 0.9652}]\u001b[0m\n",
      "\u001b[34mepoch 19:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.108, metrics={'f1': 0.9646}]\u001b[0m\n",
      "\u001b[34mepoch 19:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.108, metrics={'f1': 0.9646}]\u001b[0m\n",
      "\u001b[34mepoch 19:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.108, metrics={'f1': 0.9646}]\u001b[0m\n",
      "\u001b[34mepoch 19:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.0998, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mepoch 19: 100%|██████████| 8/8 [00:03<00:00,  2.82it/s, loss=0.0998, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mepoch 19: 100%|██████████| 8/8 [00:03<00:00,  2.01it/s, loss=0.0998, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0254, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.27it/s, loss=0.0254, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.27it/s, loss=0.0254, metrics={'f1': 0.9855}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.27it/s, loss=0.0242, metrics={'f1': 0.9927}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.02it/s, loss=0.0242, metrics={'f1': 0.9927}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.02it/s, loss=0.0242, metrics={'f1': 0.9927}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.02it/s, loss=0.0201, metrics={'f1': 0.9951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.02it/s, loss=0.0201, metrics={'f1': 0.9951}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.02it/s, loss=0.0207, metrics={'f1': 0.9942}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.01it/s, loss=0.0207, metrics={'f1': 0.9942}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.01it/s, loss=0.0207, metrics={'f1': 0.9942}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.01it/s, loss=0.0245, metrics={'f1': 0.9922}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.01it/s, loss=0.0245, metrics={'f1': 0.9922}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.01it/s, loss=0.0232, metrics={'f1': 0.9922}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.38it/s, loss=0.0232, metrics={'f1': 0.9922}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.38it/s, loss=0.0232, metrics={'f1': 0.9922}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.38it/s, loss=0.0239, metrics={'f1': 0.9914}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.38it/s, loss=0.0239, metrics={'f1': 0.9914}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.38it/s, loss=0.0214, metrics={'f1': 0.9916}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 11.45it/s, loss=0.0214, metrics={'f1': 0.9916}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.29it/s, loss=0.0214, metrics={'f1': 0.9916}]\u001b[0m\n",
      "\u001b[34mINFO:root:Training is completed.\u001b[0m\n",
      "\u001b[34mINFO:root:Saving model...\u001b[0m\n",
      "\u001b[34m2023-07-04 07:06:17,114 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-07-04 07:06:19 Uploading - Uploading generated training model\n",
      "2023-07-04 07:06:40 Completed - Training job completed\n",
      "Training seconds: 224\n",
      "Billable seconds: 224\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-{train_model_id}-training\")\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "\n",
    "# Override the number of epochs hyperparameter with custom values\n",
    "\n",
    "hyperparameters['n_epochs'] = \"19\"\n",
    "hyperparameters['learning_rate'] = 0.0015378552188176709\n",
    "hyperparameters['batch_size'] = 128\n",
    "hyperparameters['attn_dropout'] = 0.23174447846243657\n",
    "hyperparameters['mlp_dropout'] = 0.530977533537545\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Training job by passing s3 path of the training data\n",
    "tabular_estimator.fit(\n",
    "    {\"training\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, \n",
    "    logs=True, job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c25152",
   "metadata": {},
   "source": [
    "As we did before, we deploy a model for inference and then generate predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73732b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-west-1-378421839225/tabular-training/output/jumpstart-pytorch-tabtransformerclassif-2023-07-04-07-01-15-639/output/model.tar.gz), script artifact (s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/inference/tabtransformerclassification/v1.0.2/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-west-1-378421839225/sagemaker-jumpstart-2023-07-04-07-23-21-901/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: sagemaker-jumpstart-2023-07-04-07-23-21-901\n",
      "INFO:sagemaker:Creating endpoint-config with name jumpstart-inference-pytorch-tabtransfor-2023-07-04-07-23-21-901\n",
      "INFO:sagemaker:Creating endpoint with name jumpstart-inference-pytorch-tabtransfor-2023-07-04-07-23-21-901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-inference-{train_model_id}\")\n",
    "\n",
    "# Use estimator with best hyperparameters from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tabular_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0919aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "test_df = pd.read_csv(TEST_DATA)\n",
    "test_df['EJ_B'] = (test_df['EJ'] == 'B').astype('int')\n",
    "X_test = test_df.drop(columns=['Id', 'EJ'])\n",
    "\n",
    "df_test = pd.concat([X_test], axis=1)\n",
    "df_test.columns = [f\"Feature_{i}\" for i in range(df_test.shape[1])]\n",
    "\n",
    "# prepare the predicting features to send into the endpoint.\n",
    "features = df_test.iloc[:, :]\n",
    "\n",
    "# make predictions\n",
    "query_response_batch = query_endpoint(\n",
    "    features.iloc[:, :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "predict_prob = parse_response(query_response_batch)  # prediction probability per batch\n",
    "predict_label = np.argmax(predict_prob, axis=1)\n",
    "\n",
    "# store the test-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob).to_csv(\"test_pred_probs/amzn-tab-trans.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d99162f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: sagemaker-jumpstart-2023-07-04-07-23-21-901\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: jumpstart-inference-pytorch-tabtransfor-2023-07-04-07-23-21-901\n",
      "INFO:sagemaker:Deleting endpoint with name: jumpstart-inference-pytorch-tabtransfor-2023-07-04-07-23-21-901\n"
     ]
    }
   ],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
