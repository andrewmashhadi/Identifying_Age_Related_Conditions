{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d232297",
   "metadata": {},
   "source": [
    "# Tabular classification with Amazon SageMaker TabTransformer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3a271",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbac955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51216b",
   "metadata": {},
   "source": [
    "## First, we store the training and validation data in S3 as instructed by AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeea8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all paths to data from local storage location\n",
    "TRAIN_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'train.csv'\n",
    "TEST_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'test.csv'\n",
    "GREEKS_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'greeks.csv'\n",
    "\n",
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# train-validation split \n",
    "X_train_raw, X_val, y_train_raw, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_val['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_val = X_val.fillna(value=X_train_raw.mean())\n",
    "\n",
    "X_train_raw['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_train_raw = X_train_raw.fillna(value=X_train_raw.mean())\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "oversample = SMOTE(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "np.random.seed(77)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]\n",
    "\n",
    "# create df for train and val as instructed by aws\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "df_val = pd.concat([y_val, X_val], axis=1)\n",
    "df_val = df_val.dropna()\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    os.mkdir('train')\n",
    "\n",
    "df_train.to_csv('train/data.csv', index=False, header=False)\n",
    "\n",
    "if not os.path.exists('validation'):\n",
    "    os.mkdir('validation')\n",
    "\n",
    "df_val.to_csv('validation/data.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "# Upload the files to s3\n",
    "s3 = boto3.resource('s3')\n",
    "response = s3.meta.client.upload_file('train/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/train/data.csv')\n",
    "\n",
    "response = s3.meta.client.upload_file('validation/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/validation/data.csv')\n",
    "\n",
    "\n",
    "# remove files and directories locally\n",
    "os.remove('train/data.csv')\n",
    "os.remove('validation/data.csv')\n",
    "os.rmdir('train')\n",
    "os.rmdir('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f05d4",
   "metadata": {},
   "source": [
    "## Next, we set up a SageMaker training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade4907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto3.session.Session(region_name='us-west-1'))\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_role = 'arn:aws:iam::378421839225:role/service-role/AmazonSageMaker-ExecutionRole-20230623T185897'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09049994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "train_model_id, train_model_version, train_scope = (\n",
    "    \"pytorch-tabtransformerclassification-model\",\n",
    "    \"*\",\n",
    "    \"training\",\n",
    ")\n",
    "training_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune. In tabular case, however, the pre-trained model tarball is dummy and fine-tune means training from scratch.\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47078a",
   "metadata": {},
   "source": [
    "### Set Training Parameters\n",
    "\n",
    "---\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to train our tabular algorithm. To begin, we create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training.\n",
    "\n",
    "The second set of parameters are model, or algorithm, specific training hyperparameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a60a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = \"mypersonalprojectdata\"\n",
    "training_data_prefix = \"ICR-Data/train\"\n",
    "validation_data_prefix = \"ICR-Data/validation\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{data_bucket}/{training_data_prefix}\"\n",
    "validation_dataset_s3_path = f\"s3://{data_bucket}/{validation_data_prefix}\"\n",
    "\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"tabular-training\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07adda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the model specific specific hyperparameters, we start by fetching a python dictionary of the training hyperparameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e426b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': '15', 'patience': '10', 'learning_rate': '0.001', 'batch_size': '256', 'input_dim': '32', 'n_blocks': '4', 'attn_dropout': '0.2', 'mlp_dropout': '0.1', 'frac_shared_embed': '0.25'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# Override the number of epochs hyperparameter with custom values\n",
    "hyperparameters[\"n_epochs\"] = \"15\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fe56c",
   "metadata": {},
   "source": [
    "# We move on to train with automatic model tuning  \n",
    "\n",
    "We use a HyperparameterTuner object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a58757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "use_amt = True\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.01, scaling_type=\"Auto\"),\n",
    "    \"batch_size\": CategoricalParameter([128, 256, 512]),\n",
    "    \"attn_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "    \"mlp_dropout\": ContinuousParameter(0.0, 0.8, scaling_type=\"Auto\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00983ba",
   "metadata": {},
   "source": [
    "---\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f3d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-{train_model_id}-training\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=1200,\n",
    "    max_retry_attempts=3,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69bb3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# tune hyper-parameters with instances in AWS\n",
    "tuner = HyperparameterTuner(\n",
    "    tabular_estimator,\n",
    "    \"f1_score\",\n",
    "    hyperparameter_ranges,\n",
    "    [{\"Name\": \"f1_score\", \"Regex\": \"metrics={'f1': (\\\\S+)}\"}],\n",
    "    max_jobs=10,  # increase the max_jobs to achieve better performance from hyperparameter tuning\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type=\"Maximize\",\n",
    "    base_tuning_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "tuner.fit({\"training\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a0adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best training job: jumpstart-pytorch-ta-230729-1203-001-4d9f2ac5\n"
     ]
    }
   ],
   "source": [
    "print(f'The best training job: {tuner.best_training_job()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46064452",
   "metadata": {},
   "source": [
    "The \"best\" hyperparameters can be seen on the AWS console. The following is from the best training job (001) with the highest `f1_score` of 0.8461999893188477:\n",
    "\n",
    "- `attn_dropout=0.1366675096371158`\n",
    "- `batch_size=128`\n",
    "- `frac_shared_embed=\"0.25\"`\n",
    "- `input_dim=\"32\"`\n",
    "- `learning_rate=0.002492988535620627`\n",
    "- `mlp_dropout=0.49012177472333396`\n",
    "- `n_blocks=\"4\"`\n",
    "- `n_epochs=\"15\"`\n",
    "- `patience=\"10\"`\n",
    "- `sagemaker_container_log_level=20`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb57b46",
   "metadata": {},
   "source": [
    "We now deploy and run inference on the trained TabTransformer model for the ICR validation data to store the predictions to use in other ensemble models.\n",
    "\n",
    "---\n",
    "\n",
    "The model will output the probability of the sample for each class in the model (2 classes). We start by retrieving the jumpstart artifacts and deploying the `tuner` that we trained.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f4cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-07-29 19:07:53 Starting - Preparing the instances for training\n",
      "2023-07-29 19:07:53 Downloading - Downloading input data\n",
      "2023-07-29 19:07:53 Training - Training image download completed. Training in progress.\n",
      "2023-07-29 19:07:53 Uploading - Uploading generated training model\n",
      "2023-07-29 19:07:53 Completed - Resource reused by training job: jumpstart-pytorch-ta-230729-1203-007-1b94610a\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-inference-{train_model_id}\")\n",
    "\n",
    "# Use estimator with best hyperparameters from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f97980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe test dataset contains 124 examples and 57 columns.\u001b[0m\n",
      "\n",
      "\u001b[1mThe first 5 observations of the data: \u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_47</th>\n",
       "      <th>Feature_48</th>\n",
       "      <th>Feature_49</th>\n",
       "      <th>Feature_50</th>\n",
       "      <th>Feature_51</th>\n",
       "      <th>Feature_52</th>\n",
       "      <th>Feature_53</th>\n",
       "      <th>Feature_54</th>\n",
       "      <th>Feature_55</th>\n",
       "      <th>Feature_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478576</td>\n",
       "      <td>5192.25520</td>\n",
       "      <td>194.576478</td>\n",
       "      <td>13.230384</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>7.290957</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.705080</td>\n",
       "      <td>8.588216</td>\n",
       "      <td>...</td>\n",
       "      <td>10.690335</td>\n",
       "      <td>1.85861</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>12.418170</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>434.357883</td>\n",
       "      <td>34.411808</td>\n",
       "      <td>36.769312</td>\n",
       "      <td>0.050038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1.096024</td>\n",
       "      <td>4348.11080</td>\n",
       "      <td>546.489750</td>\n",
       "      <td>72.469800</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.167092</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>13.381312</td>\n",
       "      <td>...</td>\n",
       "      <td>5.760795</td>\n",
       "      <td>2.02884</td>\n",
       "      <td>0.182871</td>\n",
       "      <td>12.283291</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2184.856740</td>\n",
       "      <td>33.204344</td>\n",
       "      <td>40.169496</td>\n",
       "      <td>0.077344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307656</td>\n",
       "      <td>3039.47402</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.534221</td>\n",
       "      <td>8.715528</td>\n",
       "      <td>5.262246</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>11.665002</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>7.534620</td>\n",
       "      <td>139.519779</td>\n",
       "      <td>10093.114350</td>\n",
       "      <td>30.456385</td>\n",
       "      <td>56.463116</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948606</td>\n",
       "      <td>6192.61907</td>\n",
       "      <td>99.857394</td>\n",
       "      <td>29.179934</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>7.404850</td>\n",
       "      <td>7.920556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.014797</td>\n",
       "      <td>1.04371</td>\n",
       "      <td>1.666158</td>\n",
       "      <td>17.264512</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>3595.331772</td>\n",
       "      <td>35.583923</td>\n",
       "      <td>36.584128</td>\n",
       "      <td>0.131416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1.307538</td>\n",
       "      <td>8922.64648</td>\n",
       "      <td>198.478110</td>\n",
       "      <td>123.582688</td>\n",
       "      <td>13.380066</td>\n",
       "      <td>9.231078</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>16.404106</td>\n",
       "      <td>28.561792</td>\n",
       "      <td>...</td>\n",
       "      <td>6.015965</td>\n",
       "      <td>0.71224</td>\n",
       "      <td>0.331877</td>\n",
       "      <td>10.101972</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>4973.463261</td>\n",
       "      <td>46.062259</td>\n",
       "      <td>47.428966</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target  Feature_1   Feature_2   Feature_3   Feature_4  Feature_5  \\\n",
       "49        1   0.478576  5192.25520  194.576478   13.230384   8.138688   \n",
       "581       0   1.096024  4348.11080  546.489750   72.469800   8.138688   \n",
       "82        0   0.307656  3039.47402   85.200147   14.534221   8.715528   \n",
       "304       1   0.948606  6192.61907   99.857394   29.179934   8.138688   \n",
       "109       1   1.307538  8922.64648  198.478110  123.582688  13.380066   \n",
       "\n",
       "     Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_47  Feature_48  \\\n",
       "49    7.290957   0.025578   9.705080   8.588216  ...   10.690335     1.85861   \n",
       "581   3.167092   0.102921   3.396778  13.381312  ...    5.760795     2.02884   \n",
       "82    5.262246   0.031668  11.665002   1.229900  ...    0.173229     0.49706   \n",
       "304   3.632190   0.025578   7.404850   7.920556  ...    5.014797     1.04371   \n",
       "109   9.231078   0.025578  16.404106  28.561792  ...    6.015965     0.71224   \n",
       "\n",
       "     Feature_49  Feature_50  Feature_51    Feature_52  Feature_53  Feature_54  \\\n",
       "49     0.067730   12.418170   72.611063    434.357883   34.411808   36.769312   \n",
       "581    0.182871   12.283291   72.611063   2184.856740   33.204344   40.169496   \n",
       "82     0.067730    7.534620  139.519779  10093.114350   30.456385   56.463116   \n",
       "304    1.666158   17.264512   72.611063   3595.331772   35.583923   36.584128   \n",
       "109    0.331877   10.101972   72.611063   4973.463261   46.062259   47.428966   \n",
       "\n",
       "     Feature_55  Feature_56  \n",
       "49     0.050038           1  \n",
       "581    0.077344           1  \n",
       "82    21.978000           0  \n",
       "304    0.131416           1  \n",
       "109    0.027720           1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up training data for predictions\n",
    "df_train.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, df_train.shape[1])]\n",
    "\n",
    "num_examples_train, num_columns_train = df_train.shape\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label_train, features_train = df_train.iloc[:, :1], df_train.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# set up validation data for predictions\n",
    "df_val.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, df_val.shape[1])]\n",
    "\n",
    "num_examples, num_columns = df_val.shape\n",
    "print(\n",
    "    f\"{bold}The test dataset contains {num_examples} examples and {num_columns} columns.{unbold}\\n\"\n",
    ")\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label, features = df_val.iloc[:, :1], df_val.iloc[:, 1:]\n",
    "\n",
    "print(f\"{bold}The first 5 observations of the data: {unbold} \\n\")\n",
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a2d1c",
   "metadata": {},
   "source": [
    "---\n",
    "The following code queries the endpoint we have created to get the predictions for the validation data. \n",
    "The `query_endpoint()` function returns an array-like of shape `(num_examples, num_classes)`, where each row indicates\n",
    "the probability of each class in the model. The `num_classes` is 2 in above test data.\n",
    "In addition, the predicted class label is obtained by taking the class label with the maximum probability over others for each example. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc8fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_tabular_data):\n",
    "    # endpoint_name = endpoint_name\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_tabular_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_probabilities = model_predictions[\"probabilities\"]\n",
    "    return np.array(predicted_probabilities)\n",
    "\n",
    "# split the train data into smaller size of batches to query the endpoint due to the large size of test data.\n",
    "batch_size = 1500\n",
    "predict_prob_train = []\n",
    "for i in np.arange(0, num_examples_train, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        features_train.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob_train.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob_train = np.concatenate(predict_prob_train, axis=0)\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint due to the large size of test data.\n",
    "batch_size = 1500\n",
    "predict_prob = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        features.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    "    )\n",
    "    predict_prob_batch = parse_response(query_response_batch)  # prediction probability per batch\n",
    "    predict_prob.append(predict_prob_batch)\n",
    "\n",
    "\n",
    "predict_prob = np.concatenate(predict_prob, axis=0)\n",
    "predict_label = np.argmax(predict_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0224fb1",
   "metadata": {},
   "source": [
    "## Evaluate the Validation Results Returned from the Endpoint\n",
    "\n",
    "---\n",
    "We evaluate the predictions returned from the endpoint by following two ways.\n",
    "\n",
    "* Visualize the predictions results by plotting the confusion matrix.\n",
    "\n",
    "* Evaluate the balanced logarithmic loss (as evaluated in the ICR -- Kaggle competition), along with a few other performance metrics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d331de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the predictions results by plotting the confusion matrix.\n",
    "conf_matrix = confusion_matrix(y_true=ground_truth_label.values, y_pred=predict_label)\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va=\"center\", ha=\"center\", size=\"xx-large\")\n",
    "\n",
    "plt.xlabel(\"Predictions\", fontsize=18)\n",
    "plt.ylabel(\"Actuals\", fontsize=18)\n",
    "plt.title(\"Confusion Matrix\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2d2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mEvaluation result on test data\u001b[0m:\n",
      "\u001b[1maccuracy_score\u001b[0m: 0.9354838709677419\n",
      "\u001b[1mF1 \u001b[0m: 0.8461538461538461\n",
      "\u001b[1mLog-Loss \u001b[0m: 0.13024372461774888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bal_log_loss(p, y):\n",
    "    ind0 = np.where(y==0)[0]\n",
    "    ind1 = np.where(y==1)[0]\n",
    "    \n",
    "    N0 = len(ind0)\n",
    "    N1 = len(ind1)\n",
    "    \n",
    "    y0 = (y==0).astype(int)\n",
    "    y1 = y.astype(int)\n",
    "    \n",
    "    return (- np.sum(y0*np.log(p[:, 0]))/N0 - np.sum(y1*np.log(p[:, 1]))/N1) / 2\n",
    "\n",
    "\n",
    "# Measure the prediction results quantitatively.\n",
    "eval_accuracy = accuracy_score(ground_truth_label.values, predict_label)\n",
    "eval_f1 = f1_score(ground_truth_label.values, predict_label)\n",
    "eval_log_loss = bal_log_loss(predict_prob, np.squeeze(ground_truth_label.values, axis=(1,)))\n",
    "\n",
    "print(\n",
    "    f\"{bold}Evaluation result on test data{unbold}:{newline}\"\n",
    "    f\"{bold}{accuracy_score.__name__}{unbold}: {eval_accuracy}{newline}\"\n",
    "    f\"{bold}F1 {unbold}: {eval_f1}{newline}\"\n",
    "    f\"{bold}Log-Loss {unbold}: {eval_log_loss}{newline}\"\n",
    ")\n",
    "\n",
    "# store the training-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob_train).to_csv(\"train_pred_probs/amzn-tab-trans.csv\", header=True, index=False)\n",
    "\n",
    "# store the validation-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob).to_csv(\"val_pred_probs/amzn-tab-trans.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f57c5",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we delete the endpoint corresponding to the trained model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff6901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe294fb",
   "metadata": {},
   "source": [
    "# Predictions for Test Set Submission\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "Using the reported hyperparameters for *jumpstart-pytorch-ta-230701-1231-003-c17981ed*, we retrain the estimator with all of the training data. Since our training data is already fairly small, this is done to not waste the relatively training data. \n",
    "\n",
    "First, we reorganize the training data such that the entire set of data is used to train and only the training data is considered during \"validation\". \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "085f0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# fill NaNs\n",
    "X['EJ_B'].fillna(value=X['EJ_B'].mode())\n",
    "X = X.fillna(value=X.mean())\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "oversample = SMOTE(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X, y)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]\n",
    "\n",
    "# create df for train and val (should be the same in this case)\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "df_val = pd.concat([y_train, X_train], axis=1)\n",
    "\n",
    "df_val = df_val.dropna()\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    os.mkdir('train')\n",
    "\n",
    "df_train.to_csv('train/data.csv', index=False, header=False)\n",
    "\n",
    "if not os.path.exists('validation'):\n",
    "    os.mkdir('validation')\n",
    "\n",
    "df_val.to_csv('validation/data.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "# Upload the files to s3\n",
    "s3 = boto3.resource('s3')\n",
    "response = s3.meta.client.upload_file('train/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/train/data.csv')\n",
    "\n",
    "response = s3.meta.client.upload_file('validation/data.csv', \n",
    "                                      'mypersonalprojectdata', \n",
    "                                      'ICR-Data/validation/data.csv')\n",
    "\n",
    "\n",
    "# remove files and directories locally\n",
    "os.remove('train/data.csv')\n",
    "os.remove('validation/data.csv')\n",
    "os.rmdir('train')\n",
    "os.rmdir('validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aff47a",
   "metadata": {},
   "source": [
    "Now we begin training with all of the available data, using the previously found \"optimal\" hyperparameters from tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd51492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: jumpstart-pytorch-tabtransformerclassif-2023-07-29-19-34-53-229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-29 19:34:55 Starting - Starting the training job...\n",
      "2023-07-29 19:35:09 Starting - Preparing the instances for training......\n",
      "2023-07-29 19:36:23 Downloading - Downloading input data\n",
      "2023-07-29 19:36:23 Training - Downloading the training image...\n",
      "2023-07-29 19:36:45 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:03,742 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:03,744 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:03,753 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:03,755 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:05,316 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/aiosignal/aiosignal-1.2.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/blis/blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/catalogue/catalogue-2.0.7-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/cramjam/cramjam-2.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/cymem/cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/distlib/distlib-0.3.4-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/einops/einops-0.4.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/fastparquet/fastparquet-0.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/filelock/filelock-3.7.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/frozenlist/frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/gensim/gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/grpcio/grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/importlib_resources/importlib_resources-5.7.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/imutils/imutils-0.5.4.tar.gz\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mProcessing ./lib/langcodes/langcodes-3.3.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/msgpack/msgpack-1.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/murmurhash/murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/numpy/numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/opencv_contrib_python/opencv_contrib_python-4.5.2.54-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pathy/pathy-0.6.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/platformdirs/platformdirs-2.5.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/preshed/preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pydantic/pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pyDeprecate/pyDeprecate-0.3.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/pytorch_widedeep/pytorch_widedeep-1.1.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/ray/ray-1.12.0-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/smart_open/smart_open-5.2.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy/spacy-3.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy_legacy/spacy_legacy-3.0.9-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/spacy_loggers/spacy_loggers-1.0.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/srsly/srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tensorboardX/tensorboardX-2.5-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/thinc/thinc-8.0.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/torchmetrics/torchmetrics-0.8.2-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/typer/typer-0.4.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/virtualenv/virtualenv-20.14.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/wasabi/wasabi-0.9.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/wrapt/wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_script_utilities/sagemaker_jumpstart_script_utilities-1.0.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from fastparquet==0.8.1->-r requirements.txt (line 8)) (2021.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from fastparquet==0.8.1->-r requirements.txt (line 8)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim==4.2.0->-r requirements.txt (line 11)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.8/site-packages (from grpcio==1.43.0->-r requirements.txt (line 12)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources==5.7.1->-r requirements.txt (line 13)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic==1.8.2->-r requirements.txt (line 23)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (5.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (1.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (4.62.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (0.24.2)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema\u001b[0m\n",
      "\u001b[34mDownloading jsonschema-4.18.4-py3-none-any.whl (80 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.15.3 in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (3.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (58.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy==3.3.0->-r requirements.txt (line 28)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy==3.3.0->-r requirements.txt (line 28)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet==0.8.1->-r requirements.txt (line 8)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet==0.8.1->-r requirements.txt (line 8)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->ray==1.12.0->-r requirements.txt (line 26)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy==3.3.0->-r requirements.txt (line 28)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema-specifications>=2023.03.6\u001b[0m\n",
      "\u001b[34mDownloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting referencing>=0.28.4\u001b[0m\n",
      "\u001b[34mDownloading referencing-0.30.0-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs\u001b[0m\n",
      "\u001b[34mDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10\u001b[0m\n",
      "\u001b[34mDownloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting rpds-py>=0.7.1\u001b[0m\n",
      "\u001b[34mDownloading rpds_py-0.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from ray==1.12.0->-r requirements.txt (line 26)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->pytorch-widedeep==1.1.1->-r requirements.txt (line 25)) (8.3.2)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: imutils\u001b[0m\n",
      "\u001b[34mBuilding wheel for imutils (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for imutils (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=6fd085bea64ba618a022d5f0154b2733d75e267320f2f0655fac3a818ade2ce5\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/fd/e4/e9/4c884662e099e733d692dbe899b279f593a41497be3c212c1d\u001b[0m\n",
      "\u001b[34mSuccessfully built imutils\u001b[0m\n",
      "\u001b[34mInstalling collected packages: rpds-py, attrs, referencing, importlib-resources, platformdirs, pkgutil-resolve-name, numpy, murmurhash, jsonschema-specifications, frozenlist, filelock, distlib, cymem, catalogue, wasabi, virtualenv, typer, srsly, smart-open, pydantic, preshed, msgpack, jsonschema, grpcio, blis, aiosignal, thinc, tensorboardX, spacy-loggers, spacy-legacy, ray, pyDeprecate, pathy, langcodes, cramjam, wrapt, torchmetrics, spacy, opencv-contrib-python, imutils, gensim, fastparquet, einops, sagemaker-jumpstart-script-utilities, pytorch-widedeep\u001b[0m\n",
      "\u001b[34mAttempting uninstall: attrs\u001b[0m\n",
      "\u001b[34mFound existing installation: attrs 21.2.0\u001b[0m\n",
      "\u001b[34mUninstalling attrs-21.2.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled attrs-21.2.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: numpy\u001b[0m\n",
      "\u001b[34mFound existing installation: numpy 1.19.1\u001b[0m\n",
      "\u001b[34mUninstalling numpy-1.19.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled numpy-1.19.1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSuccessfully installed aiosignal-1.2.0 attrs-23.1.0 blis-0.7.7 catalogue-2.0.7 cramjam-2.5.0 cymem-2.0.6 distlib-0.3.4 einops-0.4.1 fastparquet-0.8.1 filelock-3.7.0 frozenlist-1.3.0 gensim-4.2.0 grpcio-1.43.0 importlib-resources-5.7.1 imutils-0.5.4 jsonschema-4.18.4 jsonschema-specifications-2023.7.1 langcodes-3.3.0 msgpack-1.0.3 murmurhash-1.0.7 numpy-1.22.3 opencv-contrib-python-4.5.2.54 pathy-0.6.1 pkgutil-resolve-name-1.3.10 platformdirs-2.5.2 preshed-3.0.6 pyDeprecate-0.3.2 pydantic-1.8.2 pytorch-widedeep-1.1.1 ray-1.12.0 referencing-0.30.0 rpds-py-0.9.2 sagemaker-jumpstart-script-utilities-1.0.1 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 tensorboardX-2.5 thinc-8.0.15 torchmetrics-0.8.2 typer-0.4.1 virtualenv-20.14.1 wasabi-0.9.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:18,261 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:18,272 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:18,282 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-29 19:37:18,291 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"attn_dropout\": 0.1366675096371158,\n",
      "        \"batch_size\": 128,\n",
      "        \"frac_shared_embed\": \"0.25\",\n",
      "        \"input_dim\": \"32\",\n",
      "        \"learning_rate\": 0.002492988535620627,\n",
      "        \"mlp_dropout\": 0.49012177472333396,\n",
      "        \"n_blocks\": \"4\",\n",
      "        \"n_epochs\": \"15\",\n",
      "        \"patience\": \"10\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"jumpstart-pytorch-tabtransformerclassif-2023-07-29-19-34-53-229\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"attn_dropout\":0.1366675096371158,\"batch_size\":128,\"frac_shared_embed\":\"0.25\",\"input_dim\":\"32\",\"learning_rate\":0.002492988535620627,\"mlp_dropout\":0.49012177472333396,\"n_blocks\":\"4\",\"n_epochs\":\"15\",\"patience\":\"10\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"attn_dropout\":0.1366675096371158,\"batch_size\":128,\"frac_shared_embed\":\"0.25\",\"input_dim\":\"32\",\"learning_rate\":0.002492988535620627,\"mlp_dropout\":0.49012177472333396,\"n_blocks\":\"4\",\"n_epochs\":\"15\",\"patience\":\"10\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"jumpstart-pytorch-tabtransformerclassif-2023-07-29-19-34-53-229\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/transfer_learning/tabtransformerclassification/v1.0.4/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--attn_dropout\",\"0.1366675096371158\",\"--batch_size\",\"128\",\"--frac_shared_embed\",\"0.25\",\"--input_dim\",\"32\",\"--learning_rate\",\"0.002492988535620627\",\"--mlp_dropout\",\"0.49012177472333396\",\"--n_blocks\",\"4\",\"--n_epochs\",\"15\",\"--patience\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ATTN_DROPOUT=0.1366675096371158\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_FRAC_SHARED_EMBED=0.25\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.002492988535620627\u001b[0m\n",
      "\u001b[34mSM_HP_MLP_DROPOUT=0.49012177472333396\u001b[0m\n",
      "\u001b[34mSM_HP_N_BLOCKS=4\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HP_PATIENCE=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 transfer_learning.py --attn_dropout 0.1366675096371158 --batch_size 128 --frac_shared_embed 0.25 --input_dim 32 --learning_rate 0.002492988535620627 --mlp_dropout 0.49012177472333396 --n_blocks 4 --n_epochs 15 --patience 10\u001b[0m\n",
      "\u001b[34mINFO:root:Data in the validation channel is found. Reading the train and validation data from the training and validation channel, respectively.\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.723 algo-1:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug/core/tfevent/util.py:29: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\u001b[0m\n",
      "\u001b[34mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.dtype(np.bool): \"DT_BOOL\",\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.835 algo-1:48 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.835 algo-1:48 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.836 algo-1:48 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.836 algo-1:48 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.836 algo-1:48 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mepoch 1:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.948 algo-1:48 INFO hook.py:591] name:deeptabular.0.cat_and_cont_embed.cont_embed.weight count_params:1792\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.948 algo-1:48 INFO hook.py:591] name:deeptabular.0.cat_and_cont_embed.cont_embed.bias count_params:1792\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.948 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block0.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block1.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.949 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block2.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.q_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.kv_proj.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn.out_proj.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff.w_2.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.attn_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff_addnorm.ln.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_blks.transformer_block3.ff_addnorm.ln.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_0.0.weight count_params:12845056\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_0.0.bias count_params:7168\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_1.0.weight count_params:25690112\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.0.transformer_mlp.mlp.dense_layer_1.0.bias count_params:3584\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.1.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:591] name:deeptabular.1.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:593] Total Trainable Params: 38603393\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.950 algo-1:48 INFO hook.py:424] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-07-29 19:37:20.953 algo-1:48 INFO hook.py:488] Hook is writing from the hook with pid: 48\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug/core/tfevent/util.py:56: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  dtype=dtype, tensor_content=nparray_data.tostring(), tensor_shape=tps\u001b[0m\n",
      "\u001b[34mepoch 1:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.716, metrics={'f1': 0.6012}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:00<00:05,  1.27it/s, loss=0.716, metrics={'f1': 0.6012}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:00<00:05,  1.27it/s, loss=0.716, metrics={'f1': 0.6012}]\u001b[0m\n",
      "\u001b[34mepoch 1:  12%|█▎        | 1/8 [00:01<00:05,  1.27it/s, loss=23.7, metrics={'f1': 0.4351}]\u001b[0m\n",
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.59it/s, loss=23.7, metrics={'f1': 0.4351}]\u001b[0m\n",
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.59it/s, loss=23.7, metrics={'f1': 0.4351}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 1:  25%|██▌       | 2/8 [00:01<00:03,  1.59it/s, loss=20.9, metrics={'f1': 0.5517}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:01<00:02,  1.94it/s, loss=20.9, metrics={'f1': 0.5517}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:01<00:02,  1.94it/s, loss=20.9, metrics={'f1': 0.5517}]\u001b[0m\n",
      "\u001b[34mepoch 1:  38%|███▊      | 3/8 [00:02<00:02,  1.94it/s, loss=16.5, metrics={'f1': 0.5687}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.17it/s, loss=16.5, metrics={'f1': 0.5687}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.17it/s, loss=16.5, metrics={'f1': 0.5687}]\u001b[0m\n",
      "\u001b[34mepoch 1:  50%|█████     | 4/8 [00:02<00:01,  2.17it/s, loss=13.7, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=13.7, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=13.7, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34mepoch 1:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s, loss=11.6, metrics={'f1': 0.4638}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:02<00:00,  2.45it/s, loss=11.6, metrics={'f1': 0.4638}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:02<00:00,  2.45it/s, loss=11.6, metrics={'f1': 0.4638}]\u001b[0m\n",
      "\u001b[34mepoch 1:  75%|███████▌  | 6/8 [00:03<00:00,  2.45it/s, loss=10, metrics={'f1': 0.4705}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.54it/s, loss=10, metrics={'f1': 0.4705}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.54it/s, loss=10, metrics={'f1': 0.4705}]\u001b[0m\n",
      "\u001b[34mepoch 1:  88%|████████▊ | 7/8 [00:03<00:00,  2.54it/s, loss=8.87, metrics={'f1': 0.4963}]\u001b[0m\n",
      "\u001b[34mepoch 1: 100%|██████████| 8/8 [00:03<00:00,  2.71it/s, loss=8.87, metrics={'f1': 0.4963}]\u001b[0m\n",
      "\u001b[34mepoch 1: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s, loss=8.87, metrics={'f1': 0.4963}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.643, metrics={'f1': 0.7767}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.643, metrics={'f1': 0.7767}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.643, metrics={'f1': 0.7767}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.636, metrics={'f1': 0.7679}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.636, metrics={'f1': 0.7679}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.636, metrics={'f1': 0.7679}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.637, metrics={'f1': 0.7644}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.637, metrics={'f1': 0.7644}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.56it/s, loss=0.638, metrics={'f1': 0.7642}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.50it/s, loss=0.638, metrics={'f1': 0.7642}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.50it/s, loss=0.638, metrics={'f1': 0.7642}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.50it/s, loss=0.638, metrics={'f1': 0.7793}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.50it/s, loss=0.638, metrics={'f1': 0.7793}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.50it/s, loss=0.638, metrics={'f1': 0.7722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.51it/s, loss=0.638, metrics={'f1': 0.7722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.51it/s, loss=0.638, metrics={'f1': 0.7722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.51it/s, loss=0.636, metrics={'f1': 0.7762}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.51it/s, loss=0.636, metrics={'f1': 0.7762}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.51it/s, loss=0.636, metrics={'f1': 0.7785}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.50it/s, loss=0.636, metrics={'f1': 0.7785}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.41it/s, loss=0.636, metrics={'f1': 0.7785}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 2:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 2:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.664, metrics={'f1': 0.6441}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.664, metrics={'f1': 0.6441}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.664, metrics={'f1': 0.6441}]\u001b[0m\n",
      "\u001b[34mepoch 2:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.685, metrics={'f1': 0.4632}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:01<00:04,  1.26it/s, loss=0.685, metrics={'f1': 0.4632}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:01<00:04,  1.26it/s, loss=0.685, metrics={'f1': 0.4632}]\u001b[0m\n",
      "\u001b[34mepoch 2:  25%|██▌       | 2/8 [00:02<00:04,  1.26it/s, loss=0.7, metrics={'f1': 0.5818}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.7, metrics={'f1': 0.5818}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.7, metrics={'f1': 0.5818}]\u001b[0m\n",
      "\u001b[34mepoch 2:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.688, metrics={'f1': 0.5345}]\u001b[0m\n",
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.688, metrics={'f1': 0.5345}]\u001b[0m\n",
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.688, metrics={'f1': 0.5345}]\u001b[0m\n",
      "\u001b[34mepoch 2:  50%|█████     | 4/8 [00:03<00:02,  1.74it/s, loss=0.663, metrics={'f1': 0.5719}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.663, metrics={'f1': 0.5719}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.663, metrics={'f1': 0.5719}]\u001b[0m\n",
      "\u001b[34mepoch 2:  62%|██████▎   | 5/8 [00:03<00:01,  1.98it/s, loss=0.877, metrics={'f1': 0.5992}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.15it/s, loss=0.877, metrics={'f1': 0.5992}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.15it/s, loss=0.877, metrics={'f1': 0.5992}]\u001b[0m\n",
      "\u001b[34mepoch 2:  75%|███████▌  | 6/8 [00:03<00:00,  2.15it/s, loss=0.836, metrics={'f1': 0.5961}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.836, metrics={'f1': 0.5961}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.836, metrics={'f1': 0.5961}]\u001b[0m\n",
      "\u001b[34mepoch 2:  88%|████████▊ | 7/8 [00:04<00:00,  2.31it/s, loss=0.835, metrics={'f1': 0.5616}]\u001b[0m\n",
      "\u001b[34mepoch 2: 100%|██████████| 8/8 [00:04<00:00,  2.55it/s, loss=0.835, metrics={'f1': 0.5616}]\u001b[0m\n",
      "\u001b[34mepoch 2: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s, loss=0.835, metrics={'f1': 0.5616}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.557, metrics={'f1': 0.4324}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.82it/s, loss=0.557, metrics={'f1': 0.4324}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.82it/s, loss=0.557, metrics={'f1': 0.4324}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.82it/s, loss=0.56, metrics={'f1': 0.5294}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.34it/s, loss=0.56, metrics={'f1': 0.5294}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.34it/s, loss=0.56, metrics={'f1': 0.5294}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.34it/s, loss=0.575, metrics={'f1': 0.5134}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.34it/s, loss=0.575, metrics={'f1': 0.5134}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.34it/s, loss=0.568, metrics={'f1': 0.497}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.65it/s, loss=0.568, metrics={'f1': 0.497}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.65it/s, loss=0.568, metrics={'f1': 0.497}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.65it/s, loss=0.579, metrics={'f1': 0.4872}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.65it/s, loss=0.579, metrics={'f1': 0.4872}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.65it/s, loss=0.585, metrics={'f1': 0.4836}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.70it/s, loss=0.585, metrics={'f1': 0.4836}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.70it/s, loss=0.585, metrics={'f1': 0.4836}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.70it/s, loss=0.582, metrics={'f1': 0.5105}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.70it/s, loss=0.582, metrics={'f1': 0.5105}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.70it/s, loss=0.579, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.81it/s, loss=0.579, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.52it/s, loss=0.579, metrics={'f1': 0.5079}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 3:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 3:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.573, metrics={'f1': 0.4211}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.573, metrics={'f1': 0.4211}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.573, metrics={'f1': 0.4211}]\u001b[0m\n",
      "\u001b[34mepoch 3:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.593, metrics={'f1': 0.661}]\u001b[0m\n",
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:01<00:05,  1.19it/s, loss=0.593, metrics={'f1': 0.661}]\u001b[0m\n",
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:01<00:05,  1.19it/s, loss=0.593, metrics={'f1': 0.661}]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 3:  25%|██▌       | 2/8 [00:02<00:05,  1.19it/s, loss=0.6, metrics={'f1': 0.6929}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.6, metrics={'f1': 0.6929}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.6, metrics={'f1': 0.6929}]\u001b[0m\n",
      "\u001b[34mepoch 3:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.605, metrics={'f1': 0.6978}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:02<00:02,  1.86it/s, loss=0.605, metrics={'f1': 0.6978}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:02<00:02,  1.86it/s, loss=0.605, metrics={'f1': 0.6978}]\u001b[0m\n",
      "\u001b[34mepoch 3:  50%|█████     | 4/8 [00:03<00:02,  1.86it/s, loss=0.6, metrics={'f1': 0.7093}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.6, metrics={'f1': 0.7093}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.6, metrics={'f1': 0.7093}]\u001b[0m\n",
      "\u001b[34mepoch 3:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.594, metrics={'f1': 0.7116}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.594, metrics={'f1': 0.7116}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.594, metrics={'f1': 0.7116}]\u001b[0m\n",
      "\u001b[34mepoch 3:  75%|███████▌  | 6/8 [00:03<00:00,  2.18it/s, loss=0.58, metrics={'f1': 0.7224}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:03<00:00,  2.27it/s, loss=0.58, metrics={'f1': 0.7224}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:03<00:00,  2.27it/s, loss=0.58, metrics={'f1': 0.7224}]\u001b[0m\n",
      "\u001b[34mepoch 3:  88%|████████▊ | 7/8 [00:04<00:00,  2.27it/s, loss=0.564, metrics={'f1': 0.7315}]\u001b[0m\n",
      "\u001b[34mepoch 3: 100%|██████████| 8/8 [00:04<00:00,  2.49it/s, loss=0.564, metrics={'f1': 0.7315}]\u001b[0m\n",
      "\u001b[34mepoch 3: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s, loss=0.564, metrics={'f1': 0.7315}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.426, metrics={'f1': 0.8155}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.426, metrics={'f1': 0.8155}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.426, metrics={'f1': 0.8155}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.61it/s, loss=0.408, metrics={'f1': 0.8091}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.28it/s, loss=0.408, metrics={'f1': 0.8091}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.28it/s, loss=0.408, metrics={'f1': 0.8091}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.28it/s, loss=0.422, metrics={'f1': 0.7953}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s, loss=0.422, metrics={'f1': 0.7953}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s, loss=0.422, metrics={'f1': 0.7953}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s, loss=0.42, metrics={'f1': 0.7901}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s, loss=0.42, metrics={'f1': 0.7901}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s, loss=0.424, metrics={'f1': 0.793}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.82it/s, loss=0.424, metrics={'f1': 0.793}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.82it/s, loss=0.424, metrics={'f1': 0.793}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.82it/s, loss=0.43, metrics={'f1': 0.7786}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.82it/s, loss=0.43, metrics={'f1': 0.7786}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.82it/s, loss=0.425, metrics={'f1': 0.7863}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.01it/s, loss=0.425, metrics={'f1': 0.7863}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00, 10.01it/s, loss=0.425, metrics={'f1': 0.7863}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:01<00:00, 10.01it/s, loss=0.421, metrics={'f1': 0.7896}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00,  7.81it/s, loss=0.421, metrics={'f1': 0.7896}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 4:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 4:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.486, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.486, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.486, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  12%|█▎        | 1/8 [00:01<00:09,  1.32s/it, loss=0.456, metrics={'f1': 0.7822}]\u001b[0m\n",
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:01<00:04,  1.30it/s, loss=0.456, metrics={'f1': 0.7822}]\u001b[0m\n",
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:01<00:04,  1.30it/s, loss=0.456, metrics={'f1': 0.7822}]\u001b[0m\n",
      "\u001b[34mepoch 4:  25%|██▌       | 2/8 [00:02<00:04,  1.30it/s, loss=0.461, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.461, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.461, metrics={'f1': 0.7706}]\u001b[0m\n",
      "\u001b[34mepoch 4:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.478, metrics={'f1': 0.7686}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.478, metrics={'f1': 0.7686}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.478, metrics={'f1': 0.7686}]\u001b[0m\n",
      "\u001b[34mepoch 4:  50%|█████     | 4/8 [00:03<00:02,  1.79it/s, loss=0.478, metrics={'f1': 0.7754}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.478, metrics={'f1': 0.7754}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.478, metrics={'f1': 0.7754}]\u001b[0m\n",
      "\u001b[34mepoch 4:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.471, metrics={'f1': 0.7769}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.21it/s, loss=0.471, metrics={'f1': 0.7769}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.21it/s, loss=0.471, metrics={'f1': 0.7769}]\u001b[0m\n",
      "\u001b[34mepoch 4:  75%|███████▌  | 6/8 [00:03<00:00,  2.21it/s, loss=0.457, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.457, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:03<00:00,  2.31it/s, loss=0.457, metrics={'f1': 0.7898}]\u001b[0m\n",
      "\u001b[34mepoch 4:  88%|████████▊ | 7/8 [00:04<00:00,  2.31it/s, loss=0.444, metrics={'f1': 0.7935}]\u001b[0m\n",
      "\u001b[34mepoch 4: 100%|██████████| 8/8 [00:04<00:00,  2.50it/s, loss=0.444, metrics={'f1': 0.7935}]\u001b[0m\n",
      "\u001b[34mepoch 4: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s, loss=0.444, metrics={'f1': 0.7935}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.334, metrics={'f1': 0.8269}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.334, metrics={'f1': 0.8269}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.334, metrics={'f1': 0.8269}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.84it/s, loss=0.32, metrics={'f1': 0.8356}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.59it/s, loss=0.32, metrics={'f1': 0.8356}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.59it/s, loss=0.32, metrics={'f1': 0.8356}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.59it/s, loss=0.341, metrics={'f1': 0.8256}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.59it/s, loss=0.341, metrics={'f1': 0.8256}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.59it/s, loss=0.334, metrics={'f1': 0.8186}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s, loss=0.334, metrics={'f1': 0.8186}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s, loss=0.334, metrics={'f1': 0.8186}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s, loss=0.335, metrics={'f1': 0.8231}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s, loss=0.335, metrics={'f1': 0.8231}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s, loss=0.341, metrics={'f1': 0.8204}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00, 10.22it/s, loss=0.341, metrics={'f1': 0.8204}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00, 10.22it/s, loss=0.341, metrics={'f1': 0.8204}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00, 10.22it/s, loss=0.336, metrics={'f1': 0.8287}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00, 10.22it/s, loss=0.336, metrics={'f1': 0.8287}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00, 10.22it/s, loss=0.335, metrics={'f1': 0.8277}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.37it/s, loss=0.335, metrics={'f1': 0.8277}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.51it/s, loss=0.335, metrics={'f1': 0.8277}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 5:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 5:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.385, metrics={'f1': 0.7961}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.385, metrics={'f1': 0.7961}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.385, metrics={'f1': 0.7961}]\u001b[0m\n",
      "\u001b[34mepoch 5:  12%|█▎        | 1/8 [00:01<00:09,  1.33s/it, loss=0.377, metrics={'f1': 0.8333}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.377, metrics={'f1': 0.8333}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:01<00:04,  1.25it/s, loss=0.377, metrics={'f1': 0.8333}]\u001b[0m\n",
      "\u001b[34mepoch 5:  25%|██▌       | 2/8 [00:02<00:04,  1.25it/s, loss=0.387, metrics={'f1': 0.8262}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.387, metrics={'f1': 0.8262}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.387, metrics={'f1': 0.8262}]\u001b[0m\n",
      "\u001b[34mepoch 5:  38%|███▊      | 3/8 [00:02<00:03,  1.59it/s, loss=0.377, metrics={'f1': 0.8305}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.377, metrics={'f1': 0.8305}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:02<00:02,  1.74it/s, loss=0.377, metrics={'f1': 0.8305}]\u001b[0m\n",
      "\u001b[34mepoch 5:  50%|█████     | 4/8 [00:03<00:02,  1.74it/s, loss=0.363, metrics={'f1': 0.8419}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.363, metrics={'f1': 0.8419}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.363, metrics={'f1': 0.8419}]\u001b[0m\n",
      "\u001b[34mepoch 5:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.364, metrics={'f1': 0.8429}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.364, metrics={'f1': 0.8429}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.364, metrics={'f1': 0.8429}]\u001b[0m\n",
      "\u001b[34mepoch 5:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.354, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:03<00:00,  2.23it/s, loss=0.354, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:03<00:00,  2.23it/s, loss=0.354, metrics={'f1': 0.8537}]\u001b[0m\n",
      "\u001b[34mepoch 5:  88%|████████▊ | 7/8 [00:04<00:00,  2.23it/s, loss=0.35, metrics={'f1': 0.8512}]\u001b[0m\n",
      "\u001b[34mepoch 5: 100%|██████████| 8/8 [00:04<00:00,  2.46it/s, loss=0.35, metrics={'f1': 0.8512}]\u001b[0m\n",
      "\u001b[34mepoch 5: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s, loss=0.35, metrics={'f1': 0.8512}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.271, metrics={'f1': 0.86}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.64it/s, loss=0.271, metrics={'f1': 0.86}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.64it/s, loss=0.271, metrics={'f1': 0.86}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.64it/s, loss=0.264, metrics={'f1': 0.88}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.264, metrics={'f1': 0.88}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.264, metrics={'f1': 0.88}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.294, metrics={'f1': 0.8646}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.294, metrics={'f1': 0.8646}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.28, metrics={'f1': 0.8698}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.59it/s, loss=0.28, metrics={'f1': 0.8698}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.59it/s, loss=0.28, metrics={'f1': 0.8698}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.59it/s, loss=0.28, metrics={'f1': 0.8678}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.59it/s, loss=0.28, metrics={'f1': 0.8678}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.59it/s, loss=0.284, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s, loss=0.284, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s, loss=0.284, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s, loss=0.278, metrics={'f1': 0.8741}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s, loss=0.278, metrics={'f1': 0.8741}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s, loss=0.279, metrics={'f1': 0.872}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.33it/s, loss=0.279, metrics={'f1': 0.872}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.21it/s, loss=0.279, metrics={'f1': 0.872}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 6:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 6:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.323, metrics={'f1': 0.8367}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:09,  1.42s/it, loss=0.323, metrics={'f1': 0.8367}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:09,  1.42s/it, loss=0.323, metrics={'f1': 0.8367}]\u001b[0m\n",
      "\u001b[34mepoch 6:  12%|█▎        | 1/8 [00:01<00:09,  1.42s/it, loss=0.295, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:01<00:05,  1.16it/s, loss=0.295, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:01<00:05,  1.16it/s, loss=0.295, metrics={'f1': 0.8711}]\u001b[0m\n",
      "\u001b[34mepoch 6:  25%|██▌       | 2/8 [00:02<00:05,  1.16it/s, loss=0.308, metrics={'f1': 0.8764}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.308, metrics={'f1': 0.8764}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.308, metrics={'f1': 0.8764}]\u001b[0m\n",
      "\u001b[34mepoch 6:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.322, metrics={'f1': 0.8706}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.322, metrics={'f1': 0.8706}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.322, metrics={'f1': 0.8706}]\u001b[0m\n",
      "\u001b[34mepoch 6:  50%|█████     | 4/8 [00:03<00:02,  1.79it/s, loss=0.304, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.97it/s, loss=0.304, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.97it/s, loss=0.304, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 6:  62%|██████▎   | 5/8 [00:03<00:01,  1.97it/s, loss=0.3, metrics={'f1': 0.8932}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.3, metrics={'f1': 0.8932}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.3, metrics={'f1': 0.8932}]\u001b[0m\n",
      "\u001b[34mepoch 6:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.295, metrics={'f1': 0.8919}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.295, metrics={'f1': 0.8919}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.295, metrics={'f1': 0.8919}]\u001b[0m\n",
      "\u001b[34mepoch 6:  88%|████████▊ | 7/8 [00:04<00:00,  2.20it/s, loss=0.29, metrics={'f1': 0.8913}]\u001b[0m\n",
      "\u001b[34mepoch 6: 100%|██████████| 8/8 [00:04<00:00,  2.44it/s, loss=0.29, metrics={'f1': 0.8913}]\u001b[0m\n",
      "\u001b[34mepoch 6: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s, loss=0.29, metrics={'f1': 0.8913}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.194, metrics={'f1': 0.9189}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.56it/s, loss=0.194, metrics={'f1': 0.9189}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.56it/s, loss=0.194, metrics={'f1': 0.9189}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.56it/s, loss=0.195, metrics={'f1': 0.925}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.35it/s, loss=0.195, metrics={'f1': 0.925}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.35it/s, loss=0.195, metrics={'f1': 0.925}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.35it/s, loss=0.2, metrics={'f1': 0.9301}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.35it/s, loss=0.2, metrics={'f1': 0.9301}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.35it/s, loss=0.19, metrics={'f1': 0.9259}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.02it/s, loss=0.19, metrics={'f1': 0.9259}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.02it/s, loss=0.19, metrics={'f1': 0.9259}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.02it/s, loss=0.183, metrics={'f1': 0.9323}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.02it/s, loss=0.183, metrics={'f1': 0.9323}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.02it/s, loss=0.189, metrics={'f1': 0.9337}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.47it/s, loss=0.189, metrics={'f1': 0.9337}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.47it/s, loss=0.189, metrics={'f1': 0.9337}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.47it/s, loss=0.189, metrics={'f1': 0.9339}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.47it/s, loss=0.189, metrics={'f1': 0.9339}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.47it/s, loss=0.192, metrics={'f1': 0.9324}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.63it/s, loss=0.192, metrics={'f1': 0.9324}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.23it/s, loss=0.192, metrics={'f1': 0.9324}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 7:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 7:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.256, metrics={'f1': 0.8929}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.256, metrics={'f1': 0.8929}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.256, metrics={'f1': 0.8929}]\u001b[0m\n",
      "\u001b[34mepoch 7:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.239, metrics={'f1': 0.9008}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.239, metrics={'f1': 0.9008}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.239, metrics={'f1': 0.9008}]\u001b[0m\n",
      "\u001b[34mepoch 7:  25%|██▌       | 2/8 [00:02<00:04,  1.21it/s, loss=0.236, metrics={'f1': 0.8978}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.236, metrics={'f1': 0.8978}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.236, metrics={'f1': 0.8978}]\u001b[0m\n",
      "\u001b[34mepoch 7:  38%|███▊      | 3/8 [00:02<00:03,  1.57it/s, loss=0.252, metrics={'f1': 0.9002}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.252, metrics={'f1': 0.9002}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:02<00:02,  1.79it/s, loss=0.252, metrics={'f1': 0.9002}]\u001b[0m\n",
      "\u001b[34mepoch 7:  50%|█████     | 4/8 [00:03<00:02,  1.79it/s, loss=0.236, metrics={'f1': 0.9145}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.236, metrics={'f1': 0.9145}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.236, metrics={'f1': 0.9145}]\u001b[0m\n",
      "\u001b[34mepoch 7:  62%|██████▎   | 5/8 [00:03<00:01,  2.04it/s, loss=0.246, metrics={'f1': 0.9107}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.23it/s, loss=0.246, metrics={'f1': 0.9107}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.23it/s, loss=0.246, metrics={'f1': 0.9107}]\u001b[0m\n",
      "\u001b[34mepoch 7:  75%|███████▌  | 6/8 [00:03<00:00,  2.23it/s, loss=0.242, metrics={'f1': 0.9121}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:03<00:00,  2.35it/s, loss=0.242, metrics={'f1': 0.9121}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:03<00:00,  2.35it/s, loss=0.242, metrics={'f1': 0.9121}]\u001b[0m\n",
      "\u001b[34mepoch 7:  88%|████████▊ | 7/8 [00:04<00:00,  2.35it/s, loss=0.241, metrics={'f1': 0.9073}]\u001b[0m\n",
      "\u001b[34mepoch 7: 100%|██████████| 8/8 [00:04<00:00,  2.55it/s, loss=0.241, metrics={'f1': 0.9073}]\u001b[0m\n",
      "\u001b[34mepoch 7: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s, loss=0.241, metrics={'f1': 0.9073}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.148, metrics={'f1': 0.9273}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s, loss=0.148, metrics={'f1': 0.9273}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s, loss=0.148, metrics={'f1': 0.9273}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s, loss=0.162, metrics={'f1': 0.9372}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s, loss=0.162, metrics={'f1': 0.9372}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s, loss=0.168, metrics={'f1': 0.9351}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  6.03it/s, loss=0.168, metrics={'f1': 0.9351}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  6.03it/s, loss=0.168, metrics={'f1': 0.9351}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  6.03it/s, loss=0.157, metrics={'f1': 0.9339}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  6.03it/s, loss=0.157, metrics={'f1': 0.9339}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  6.03it/s, loss=0.151, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s, loss=0.151, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s, loss=0.151, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s, loss=0.158, metrics={'f1': 0.9387}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s, loss=0.158, metrics={'f1': 0.9387}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s, loss=0.156, metrics={'f1': 0.9435}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.92it/s, loss=0.156, metrics={'f1': 0.9435}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.92it/s, loss=0.156, metrics={'f1': 0.9435}]\u001b[0m\n",
      "\u001b[34mvalid:  88%|████████▊ | 7/8 [00:00<00:00,  9.92it/s, loss=0.16, metrics={'f1': 0.9408}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.51it/s, loss=0.16, metrics={'f1': 0.9408}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 8:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 8:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.207, metrics={'f1': 0.9043}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.207, metrics={'f1': 0.9043}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.207, metrics={'f1': 0.9043}]\u001b[0m\n",
      "\u001b[34mepoch 8:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.18, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.18, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.18, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  25%|██▌       | 2/8 [00:02<00:04,  1.23it/s, loss=0.193, metrics={'f1': 0.9194}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.193, metrics={'f1': 0.9194}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.193, metrics={'f1': 0.9194}]\u001b[0m\n",
      "\u001b[34mepoch 8:  38%|███▊      | 3/8 [00:02<00:03,  1.55it/s, loss=0.207, metrics={'f1': 0.9109}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:02<00:02,  1.73it/s, loss=0.207, metrics={'f1': 0.9109}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:02<00:02,  1.73it/s, loss=0.207, metrics={'f1': 0.9109}]\u001b[0m\n",
      "\u001b[34mepoch 8:  50%|█████     | 4/8 [00:03<00:02,  1.73it/s, loss=0.197, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.197, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.197, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 8:  62%|██████▎   | 5/8 [00:03<00:01,  1.91it/s, loss=0.202, metrics={'f1': 0.9223}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.202, metrics={'f1': 0.9223}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.202, metrics={'f1': 0.9223}]\u001b[0m\n",
      "\u001b[34mepoch 8:  75%|███████▌  | 6/8 [00:03<00:00,  2.09it/s, loss=0.195, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.195, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s, loss=0.195, metrics={'f1': 0.9262}]\u001b[0m\n",
      "\u001b[34mepoch 8:  88%|████████▊ | 7/8 [00:04<00:00,  2.20it/s, loss=0.207, metrics={'f1': 0.9192}]\u001b[0m\n",
      "\u001b[34mepoch 8: 100%|██████████| 8/8 [00:04<00:00,  2.42it/s, loss=0.207, metrics={'f1': 0.9192}]\u001b[0m\n",
      "\u001b[34mepoch 8: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s, loss=0.207, metrics={'f1': 0.9192}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.113, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.113, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.113, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.46it/s, loss=0.134, metrics={'f1': 0.95}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.17it/s, loss=0.134, metrics={'f1': 0.95}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.17it/s, loss=0.134, metrics={'f1': 0.95}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.17it/s, loss=0.135, metrics={'f1': 0.9519}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.56it/s, loss=0.135, metrics={'f1': 0.9519}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.56it/s, loss=0.135, metrics={'f1': 0.9519}]\u001b[0m\n",
      "\u001b[34mvalid:  38%|███▊      | 3/8 [00:00<00:00,  5.56it/s, loss=0.124, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.72it/s, loss=0.124, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.72it/s, loss=0.124, metrics={'f1': 0.951}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.72it/s, loss=0.119, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.43it/s, loss=0.119, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.43it/s, loss=0.119, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  62%|██████▎   | 5/8 [00:00<00:00,  7.43it/s, loss=0.13, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.12it/s, loss=0.13, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  8.12it/s, loss=0.13, metrics={'f1': 0.9546}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:01<00:00,  8.12it/s, loss=0.128, metrics={'f1': 0.957}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:01<00:00,  8.12it/s, loss=0.128, metrics={'f1': 0.957}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:01<00:00,  8.12it/s, loss=0.133, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00,  9.63it/s, loss=0.133, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00,  7.16it/s, loss=0.133, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 9:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 9:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.198, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:10,  1.49s/it, loss=0.198, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:10,  1.49s/it, loss=0.198, metrics={'f1': 0.8868}]\u001b[0m\n",
      "\u001b[34mepoch 9:  12%|█▎        | 1/8 [00:01<00:10,  1.49s/it, loss=0.19, metrics={'f1': 0.9129}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:01<00:05,  1.11it/s, loss=0.19, metrics={'f1': 0.9129}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:01<00:05,  1.11it/s, loss=0.19, metrics={'f1': 0.9129}]\u001b[0m\n",
      "\u001b[34mepoch 9:  25%|██▌       | 2/8 [00:02<00:05,  1.11it/s, loss=0.195, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.45it/s, loss=0.195, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.45it/s, loss=0.195, metrics={'f1': 0.9243}]\u001b[0m\n",
      "\u001b[34mepoch 9:  38%|███▊      | 3/8 [00:02<00:03,  1.45it/s, loss=0.199, metrics={'f1': 0.9173}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:02<00:02,  1.67it/s, loss=0.199, metrics={'f1': 0.9173}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:02<00:02,  1.67it/s, loss=0.199, metrics={'f1': 0.9173}]\u001b[0m\n",
      "\u001b[34mepoch 9:  50%|█████     | 4/8 [00:03<00:02,  1.67it/s, loss=0.185, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.93it/s, loss=0.185, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.93it/s, loss=0.185, metrics={'f1': 0.9268}]\u001b[0m\n",
      "\u001b[34mepoch 9:  62%|██████▎   | 5/8 [00:03<00:01,  1.93it/s, loss=0.194, metrics={'f1': 0.9246}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.194, metrics={'f1': 0.9246}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:03<00:00,  2.10it/s, loss=0.194, metrics={'f1': 0.9246}]\u001b[0m\n",
      "\u001b[34mepoch 9:  75%|███████▌  | 6/8 [00:04<00:00,  2.10it/s, loss=0.188, metrics={'f1': 0.9269}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.188, metrics={'f1': 0.9269}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.188, metrics={'f1': 0.9269}]\u001b[0m\n",
      "\u001b[34mepoch 9:  88%|████████▊ | 7/8 [00:04<00:00,  2.26it/s, loss=0.19, metrics={'f1': 0.9279}]\u001b[0m\n",
      "\u001b[34mepoch 9: 100%|██████████| 8/8 [00:04<00:00,  2.51it/s, loss=0.19, metrics={'f1': 0.9279}]\u001b[0m\n",
      "\u001b[34mepoch 9: 100%|██████████| 8/8 [00:04<00:00,  1.85it/s, loss=0.19, metrics={'f1': 0.9279}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0885, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.73it/s, loss=0.0885, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.73it/s, loss=0.0885, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.73it/s, loss=0.11, metrics={'f1': 0.963}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.53it/s, loss=0.11, metrics={'f1': 0.963}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.53it/s, loss=0.11, metrics={'f1': 0.963}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.53it/s, loss=0.105, metrics={'f1': 0.9602}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.53it/s, loss=0.105, metrics={'f1': 0.9602}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.53it/s, loss=0.1, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.57it/s, loss=0.1, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.57it/s, loss=0.1, metrics={'f1': 0.9574}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.57it/s, loss=0.0988, metrics={'f1': 0.9595}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.57it/s, loss=0.0988, metrics={'f1': 0.9595}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.57it/s, loss=0.11, metrics={'f1': 0.9587}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.96it/s, loss=0.11, metrics={'f1': 0.9587}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.96it/s, loss=0.11, metrics={'f1': 0.9587}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.96it/s, loss=0.109, metrics={'f1': 0.9594}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.96it/s, loss=0.109, metrics={'f1': 0.9594}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.96it/s, loss=0.116, metrics={'f1': 0.9569}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.91it/s, loss=0.116, metrics={'f1': 0.9569}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.59it/s, loss=0.116, metrics={'f1': 0.9569}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 10:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 10:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.133, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.133, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.133, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 10:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.159, metrics={'f1': 0.9426}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.159, metrics={'f1': 0.9426}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.159, metrics={'f1': 0.9426}]\u001b[0m\n",
      "\u001b[34mepoch 10:  25%|██▌       | 2/8 [00:02<00:04,  1.22it/s, loss=0.157, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.157, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.157, metrics={'f1': 0.9474}]\u001b[0m\n",
      "\u001b[34mepoch 10:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.169, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.169, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:02<00:02,  1.72it/s, loss=0.169, metrics={'f1': 0.9384}]\u001b[0m\n",
      "\u001b[34mepoch 10:  50%|█████     | 4/8 [00:03<00:02,  1.72it/s, loss=0.164, metrics={'f1': 0.9414}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.164, metrics={'f1': 0.9414}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.164, metrics={'f1': 0.9414}]\u001b[0m\n",
      "\u001b[34mepoch 10:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.169, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:03<00:01,  1.96it/s, loss=0.169, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:03<00:01,  1.96it/s, loss=0.169, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 10:  75%|███████▌  | 6/8 [00:04<00:01,  1.96it/s, loss=0.16, metrics={'f1': 0.9463}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.16, metrics={'f1': 0.9463}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.16, metrics={'f1': 0.9463}]\u001b[0m\n",
      "\u001b[34mepoch 10:  88%|████████▊ | 7/8 [00:04<00:00,  2.14it/s, loss=0.169, metrics={'f1': 0.9421}]\u001b[0m\n",
      "\u001b[34mepoch 10: 100%|██████████| 8/8 [00:04<00:00,  2.38it/s, loss=0.169, metrics={'f1': 0.9421}]\u001b[0m\n",
      "\u001b[34mepoch 10: 100%|██████████| 8/8 [00:04<00:00,  1.84it/s, loss=0.169, metrics={'f1': 0.9421}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0607, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.69it/s, loss=0.0607, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.69it/s, loss=0.0607, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.69it/s, loss=0.0895, metrics={'f1': 0.9672}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.0895, metrics={'f1': 0.9672}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.0895, metrics={'f1': 0.9672}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.0822, metrics={'f1': 0.971}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.0822, metrics={'f1': 0.971}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.32it/s, loss=0.0792, metrics={'f1': 0.9697}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.46it/s, loss=0.0792, metrics={'f1': 0.9697}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.46it/s, loss=0.0792, metrics={'f1': 0.9697}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.46it/s, loss=0.0779, metrics={'f1': 0.9674}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.46it/s, loss=0.0779, metrics={'f1': 0.9674}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.46it/s, loss=0.0893, metrics={'f1': 0.9653}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.74it/s, loss=0.0893, metrics={'f1': 0.9653}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.74it/s, loss=0.0893, metrics={'f1': 0.9653}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.74it/s, loss=0.0884, metrics={'f1': 0.966}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.74it/s, loss=0.0884, metrics={'f1': 0.966}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.74it/s, loss=0.0938, metrics={'f1': 0.9659}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.73it/s, loss=0.0938, metrics={'f1': 0.9659}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.41it/s, loss=0.0938, metrics={'f1': 0.9659}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 11:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 11:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.147, metrics={'f1': 0.9204}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.147, metrics={'f1': 0.9204}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.147, metrics={'f1': 0.9204}]\u001b[0m\n",
      "\u001b[34mepoch 11:  12%|█▎        | 1/8 [00:01<00:09,  1.36s/it, loss=0.146, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.146, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:01<00:04,  1.21it/s, loss=0.146, metrics={'f1': 0.9286}]\u001b[0m\n",
      "\u001b[34mepoch 11:  25%|██▌       | 2/8 [00:02<00:04,  1.21it/s, loss=0.148, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.148, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.148, metrics={'f1': 0.9385}]\u001b[0m\n",
      "\u001b[34mepoch 11:  38%|███▊      | 3/8 [00:02<00:03,  1.52it/s, loss=0.137, metrics={'f1': 0.9465}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:02<00:02,  1.73it/s, loss=0.137, metrics={'f1': 0.9465}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:02<00:02,  1.73it/s, loss=0.137, metrics={'f1': 0.9465}]\u001b[0m\n",
      "\u001b[34mepoch 11:  50%|█████     | 4/8 [00:03<00:02,  1.73it/s, loss=0.128, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.128, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.128, metrics={'f1': 0.9524}]\u001b[0m\n",
      "\u001b[34mepoch 11:  62%|██████▎   | 5/8 [00:03<00:01,  1.92it/s, loss=0.132, metrics={'f1': 0.954}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.132, metrics={'f1': 0.954}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.132, metrics={'f1': 0.954}]\u001b[0m\n",
      "\u001b[34mepoch 11:  75%|███████▌  | 6/8 [00:03<00:00,  2.07it/s, loss=0.133, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:03<00:00,  2.23it/s, loss=0.133, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:03<00:00,  2.23it/s, loss=0.133, metrics={'f1': 0.9552}]\u001b[0m\n",
      "\u001b[34mepoch 11:  88%|████████▊ | 7/8 [00:04<00:00,  2.23it/s, loss=0.14, metrics={'f1': 0.9523}]\u001b[0m\n",
      "\u001b[34mepoch 11: 100%|██████████| 8/8 [00:04<00:00,  2.58it/s, loss=0.14, metrics={'f1': 0.9523}]\u001b[0m\n",
      "\u001b[34mepoch 11: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s, loss=0.14, metrics={'f1': 0.9523}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.052, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.32it/s, loss=0.052, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.32it/s, loss=0.052, metrics={'f1': 0.9821}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:03,  2.32it/s, loss=0.0894, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.98it/s, loss=0.0894, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.98it/s, loss=0.0894, metrics={'f1': 0.9627}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.98it/s, loss=0.082, metrics={'f1': 0.9651}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.98it/s, loss=0.082, metrics={'f1': 0.9651}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  3.98it/s, loss=0.074, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.89it/s, loss=0.074, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.89it/s, loss=0.074, metrics={'f1': 0.9691}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.89it/s, loss=0.0704, metrics={'f1': 0.9731}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.89it/s, loss=0.0704, metrics={'f1': 0.9731}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  6.89it/s, loss=0.0761, metrics={'f1': 0.9712}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.37it/s, loss=0.0761, metrics={'f1': 0.9712}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.37it/s, loss=0.0761, metrics={'f1': 0.9712}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.37it/s, loss=0.074, metrics={'f1': 0.9711}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.37it/s, loss=0.074, metrics={'f1': 0.9711}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:01<00:00,  9.37it/s, loss=0.0801, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00, 10.51it/s, loss=0.0801, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:01<00:00,  7.97it/s, loss=0.0801, metrics={'f1': 0.9663}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 12:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 12:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.0937, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.0937, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.0937, metrics={'f1': 0.9464}]\u001b[0m\n",
      "\u001b[34mepoch 12:  12%|█▎        | 1/8 [00:01<00:09,  1.38s/it, loss=0.135, metrics={'f1': 0.9333}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:01<00:04,  1.27it/s, loss=0.135, metrics={'f1': 0.9333}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:01<00:04,  1.27it/s, loss=0.135, metrics={'f1': 0.9333}]\u001b[0m\n",
      "\u001b[34mepoch 12:  25%|██▌       | 2/8 [00:02<00:04,  1.27it/s, loss=0.125, metrics={'f1': 0.9409}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.125, metrics={'f1': 0.9409}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.125, metrics={'f1': 0.9409}]\u001b[0m\n",
      "\u001b[34mepoch 12:  38%|███▊      | 3/8 [00:02<00:03,  1.58it/s, loss=0.12, metrics={'f1': 0.9487}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:02<00:02,  1.75it/s, loss=0.12, metrics={'f1': 0.9487}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:02<00:02,  1.75it/s, loss=0.12, metrics={'f1': 0.9487}]\u001b[0m\n",
      "\u001b[34mepoch 12:  50%|█████     | 4/8 [00:03<00:02,  1.75it/s, loss=0.127, metrics={'f1': 0.9485}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.127, metrics={'f1': 0.9485}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.127, metrics={'f1': 0.9485}]\u001b[0m\n",
      "\u001b[34mepoch 12:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.136, metrics={'f1': 0.9429}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.136, metrics={'f1': 0.9429}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.136, metrics={'f1': 0.9429}]\u001b[0m\n",
      "\u001b[34mepoch 12:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.13, metrics={'f1': 0.947}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:03<00:00,  2.18it/s, loss=0.13, metrics={'f1': 0.947}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:03<00:00,  2.18it/s, loss=0.13, metrics={'f1': 0.947}]\u001b[0m\n",
      "\u001b[34mepoch 12:  88%|████████▊ | 7/8 [00:04<00:00,  2.18it/s, loss=0.135, metrics={'f1': 0.9436}]\u001b[0m\n",
      "\u001b[34mepoch 12: 100%|██████████| 8/8 [00:04<00:00,  2.52it/s, loss=0.135, metrics={'f1': 0.9436}]\u001b[0m\n",
      "\u001b[34mepoch 12: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s, loss=0.135, metrics={'f1': 0.9436}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0671, metrics={'f1': 0.9725}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.77it/s, loss=0.0671, metrics={'f1': 0.9725}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.77it/s, loss=0.0671, metrics={'f1': 0.9725}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.77it/s, loss=0.104, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.60it/s, loss=0.104, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.60it/s, loss=0.104, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.60it/s, loss=0.105, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.60it/s, loss=0.105, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.60it/s, loss=0.0965, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.18it/s, loss=0.0965, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.18it/s, loss=0.0965, metrics={'f1': 0.9645}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.18it/s, loss=0.0921, metrics={'f1': 0.9679}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.18it/s, loss=0.0921, metrics={'f1': 0.9679}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.18it/s, loss=0.0973, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s, loss=0.0973, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s, loss=0.0973, metrics={'f1': 0.9654}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s, loss=0.0902, metrics={'f1': 0.9695}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s, loss=0.0902, metrics={'f1': 0.9695}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s, loss=0.0925, metrics={'f1': 0.9668}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.85it/s, loss=0.0925, metrics={'f1': 0.9668}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.50it/s, loss=0.0925, metrics={'f1': 0.9668}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mepoch 13:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 13:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.114, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.114, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.114, metrics={'f1': 0.9434}]\u001b[0m\n",
      "\u001b[34mepoch 13:  12%|█▎        | 1/8 [00:01<00:09,  1.37s/it, loss=0.117, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:01<00:05,  1.19it/s, loss=0.117, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:01<00:05,  1.19it/s, loss=0.117, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mepoch 13:  25%|██▌       | 2/8 [00:02<00:05,  1.19it/s, loss=0.11, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.11, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.11, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  38%|███▊      | 3/8 [00:02<00:03,  1.51it/s, loss=0.12, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:02<00:02,  1.68it/s, loss=0.12, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:02<00:02,  1.68it/s, loss=0.12, metrics={'f1': 0.9572}]\u001b[0m\n",
      "\u001b[34mepoch 13:  50%|█████     | 4/8 [00:03<00:02,  1.68it/s, loss=0.116, metrics={'f1': 0.9626}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.116, metrics={'f1': 0.9626}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.116, metrics={'f1': 0.9626}]\u001b[0m\n",
      "\u001b[34mepoch 13:  62%|██████▎   | 5/8 [00:03<00:01,  1.88it/s, loss=0.116, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.116, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.116, metrics={'f1': 0.9638}]\u001b[0m\n",
      "\u001b[34mepoch 13:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.113, metrics={'f1': 0.9657}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:03<00:00,  2.21it/s, loss=0.113, metrics={'f1': 0.9657}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:03<00:00,  2.21it/s, loss=0.113, metrics={'f1': 0.9657}]\u001b[0m\n",
      "\u001b[34mepoch 13:  88%|████████▊ | 7/8 [00:04<00:00,  2.21it/s, loss=0.114, metrics={'f1': 0.9615}]\u001b[0m\n",
      "\u001b[34mepoch 13: 100%|██████████| 8/8 [00:04<00:00,  2.43it/s, loss=0.114, metrics={'f1': 0.9615}]\u001b[0m\n",
      "\u001b[34mepoch 13: 100%|██████████| 8/8 [00:04<00:00,  1.85it/s, loss=0.114, metrics={'f1': 0.9615}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.0505, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.74it/s, loss=0.0505, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.74it/s, loss=0.0505, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.74it/s, loss=0.0971, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.50it/s, loss=0.0971, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.50it/s, loss=0.0971, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.50it/s, loss=0.0899, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.50it/s, loss=0.0899, metrics={'f1': 0.962}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.50it/s, loss=0.0804, metrics={'f1': 0.9687}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.26it/s, loss=0.0804, metrics={'f1': 0.9687}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.26it/s, loss=0.0804, metrics={'f1': 0.9687}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.26it/s, loss=0.0775, metrics={'f1': 0.9712}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.26it/s, loss=0.0775, metrics={'f1': 0.9712}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.26it/s, loss=0.0781, metrics={'f1': 0.9722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.0781, metrics={'f1': 0.9722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.0781, metrics={'f1': 0.9722}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.0734, metrics={'f1': 0.9752}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.0734, metrics={'f1': 0.9752}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.12it/s, loss=0.0797, metrics={'f1': 0.9699}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  9.92it/s, loss=0.0797, metrics={'f1': 0.9699}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.05it/s, loss=0.0797, metrics={'f1': 0.9699}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 14:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 14:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.0935, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.0935, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.0935, metrics={'f1': 0.9636}]\u001b[0m\n",
      "\u001b[34mepoch 14:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.122, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.122, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:01<00:04,  1.23it/s, loss=0.122, metrics={'f1': 0.9536}]\u001b[0m\n",
      "\u001b[34mepoch 14:  25%|██▌       | 2/8 [00:02<00:04,  1.23it/s, loss=0.0997, metrics={'f1': 0.9679}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.0997, metrics={'f1': 0.9679}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.0997, metrics={'f1': 0.9679}]\u001b[0m\n",
      "\u001b[34mepoch 14:  38%|███▊      | 3/8 [00:02<00:03,  1.62it/s, loss=0.118, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.118, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:02<00:02,  1.78it/s, loss=0.118, metrics={'f1': 0.9576}]\u001b[0m\n",
      "\u001b[34mepoch 14:  50%|█████     | 4/8 [00:03<00:02,  1.78it/s, loss=0.116, metrics={'f1': 0.9614}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.116, metrics={'f1': 0.9614}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.116, metrics={'f1': 0.9614}]\u001b[0m\n",
      "\u001b[34mepoch 14:  62%|██████▎   | 5/8 [00:03<00:01,  1.90it/s, loss=0.113, metrics={'f1': 0.9616}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.113, metrics={'f1': 0.9616}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.113, metrics={'f1': 0.9616}]\u001b[0m\n",
      "\u001b[34mepoch 14:  75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s, loss=0.106, metrics={'f1': 0.964}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:03<00:00,  2.19it/s, loss=0.106, metrics={'f1': 0.964}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:03<00:00,  2.19it/s, loss=0.106, metrics={'f1': 0.964}]\u001b[0m\n",
      "\u001b[34mepoch 14:  88%|████████▊ | 7/8 [00:04<00:00,  2.19it/s, loss=0.108, metrics={'f1': 0.9609}]\u001b[0m\n",
      "\u001b[34mepoch 14: 100%|██████████| 8/8 [00:04<00:00,  2.45it/s, loss=0.108, metrics={'f1': 0.9609}]\u001b[0m\n",
      "\u001b[34mepoch 14: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s, loss=0.108, metrics={'f1': 0.9609}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.116, metrics={'f1': 0.9231}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.78it/s, loss=0.116, metrics={'f1': 0.9231}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.78it/s, loss=0.116, metrics={'f1': 0.9231}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.78it/s, loss=0.159, metrics={'f1': 0.9156}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.39it/s, loss=0.159, metrics={'f1': 0.9156}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.39it/s, loss=0.159, metrics={'f1': 0.9156}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.39it/s, loss=0.171, metrics={'f1': 0.9143}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.39it/s, loss=0.171, metrics={'f1': 0.9143}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.39it/s, loss=0.151, metrics={'f1': 0.9234}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.53it/s, loss=0.151, metrics={'f1': 0.9234}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.53it/s, loss=0.151, metrics={'f1': 0.9234}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.53it/s, loss=0.143, metrics={'f1': 0.9316}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.53it/s, loss=0.143, metrics={'f1': 0.9316}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.53it/s, loss=0.145, metrics={'f1': 0.9322}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.89it/s, loss=0.145, metrics={'f1': 0.9322}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.89it/s, loss=0.145, metrics={'f1': 0.9322}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.89it/s, loss=0.131, metrics={'f1': 0.9404}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.89it/s, loss=0.131, metrics={'f1': 0.9404}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.89it/s, loss=0.134, metrics={'f1': 0.9374}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.98it/s, loss=0.134, metrics={'f1': 0.9374}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.58it/s, loss=0.134, metrics={'f1': 0.9374}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 15:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mepoch 15:   0%|          | 0/8 [00:01<?, ?it/s, loss=0.145, metrics={'f1': 0.8911}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.145, metrics={'f1': 0.8911}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.145, metrics={'f1': 0.8911}]\u001b[0m\n",
      "\u001b[34mepoch 15:  12%|█▎        | 1/8 [00:01<00:09,  1.35s/it, loss=0.163, metrics={'f1': 0.9123}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.163, metrics={'f1': 0.9123}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:01<00:04,  1.22it/s, loss=0.163, metrics={'f1': 0.9123}]\u001b[0m\n",
      "\u001b[34mepoch 15:  25%|██▌       | 2/8 [00:02<00:04,  1.22it/s, loss=0.142, metrics={'f1': 0.9319}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.142, metrics={'f1': 0.9319}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.142, metrics={'f1': 0.9319}]\u001b[0m\n",
      "\u001b[34mepoch 15:  38%|███▊      | 3/8 [00:02<00:03,  1.56it/s, loss=0.129, metrics={'f1': 0.94}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:02<00:02,  1.77it/s, loss=0.129, metrics={'f1': 0.94}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:02<00:02,  1.77it/s, loss=0.129, metrics={'f1': 0.94}]\u001b[0m\n",
      "\u001b[34mepoch 15:  50%|█████     | 4/8 [00:03<00:02,  1.77it/s, loss=0.12, metrics={'f1': 0.948}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.12, metrics={'f1': 0.948}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.12, metrics={'f1': 0.948}]\u001b[0m\n",
      "\u001b[34mepoch 15:  62%|██████▎   | 5/8 [00:03<00:01,  1.89it/s, loss=0.132, metrics={'f1': 0.9471}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.132, metrics={'f1': 0.9471}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.132, metrics={'f1': 0.9471}]\u001b[0m\n",
      "\u001b[34mepoch 15:  75%|███████▌  | 6/8 [00:03<00:00,  2.13it/s, loss=0.12, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:03<00:00,  2.27it/s, loss=0.12, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:03<00:00,  2.27it/s, loss=0.12, metrics={'f1': 0.9538}]\u001b[0m\n",
      "\u001b[34mepoch 15:  88%|████████▊ | 7/8 [00:04<00:00,  2.27it/s, loss=0.115, metrics={'f1': 0.9539}]\u001b[0m\n",
      "\u001b[34mepoch 15: 100%|██████████| 8/8 [00:04<00:00,  2.49it/s, loss=0.115, metrics={'f1': 0.9539}]\u001b[0m\n",
      "\u001b[34mepoch 15: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s, loss=0.115, metrics={'f1': 0.9539}]\u001b[0m\n",
      "\u001b[34m0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mvalid:   0%|          | 0/8 [00:00<?, ?it/s, loss=0.059, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.60it/s, loss=0.059, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.60it/s, loss=0.059, metrics={'f1': 0.9818}]\u001b[0m\n",
      "\u001b[34mvalid:  12%|█▎        | 1/8 [00:00<00:02,  2.60it/s, loss=0.0741, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.0741, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.0741, metrics={'f1': 0.9661}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.0967, metrics={'f1': 0.9503}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.0967, metrics={'f1': 0.9503}]\u001b[0m\n",
      "\u001b[34mvalid:  25%|██▌       | 2/8 [00:00<00:01,  4.44it/s, loss=0.0875, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.28it/s, loss=0.0875, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.28it/s, loss=0.0875, metrics={'f1': 0.9532}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.28it/s, loss=0.0949, metrics={'f1': 0.9525}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.28it/s, loss=0.0949, metrics={'f1': 0.9525}]\u001b[0m\n",
      "\u001b[34mvalid:  50%|█████     | 4/8 [00:00<00:00,  7.28it/s, loss=0.0968, metrics={'f1': 0.9511}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.68it/s, loss=0.0968, metrics={'f1': 0.9511}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.68it/s, loss=0.0968, metrics={'f1': 0.9511}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.68it/s, loss=0.0891, metrics={'f1': 0.9562}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.68it/s, loss=0.0891, metrics={'f1': 0.9562}]\u001b[0m\n",
      "\u001b[34mvalid:  75%|███████▌  | 6/8 [00:00<00:00,  9.68it/s, loss=0.0896, metrics={'f1': 0.9527}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00, 10.70it/s, loss=0.0896, metrics={'f1': 0.9527}]\u001b[0m\n",
      "\u001b[34mvalid: 100%|██████████| 8/8 [00:00<00:00,  8.36it/s, loss=0.0896, metrics={'f1': 0.9527}]\u001b[0m\n",
      "\u001b[34mINFO:root:Training is completed.\u001b[0m\n",
      "\u001b[34mINFO:root:Saving model...\u001b[0m\n",
      "\u001b[34m2023-07-29 19:38:41,124 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-07-29 19:39:01 Uploading - Uploading generated training model\n",
      "2023-07-29 19:39:01 Completed - Training job completed\n",
      "Training seconds: 178\n",
      "Billable seconds: 178\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-{train_model_id}-training\")\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "\n",
    "# Override the number of epochs hyperparameter with custom values\n",
    "\n",
    "hyperparameters['n_epochs'] = \"15\"\n",
    "hyperparameters['learning_rate'] = 0.002492988535620627\n",
    "hyperparameters['batch_size'] = 128\n",
    "hyperparameters['attn_dropout'] = 0.1366675096371158\n",
    "hyperparameters['mlp_dropout'] = 0.49012177472333396\n",
    "\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Training job by passing s3 path of the training data\n",
    "tabular_estimator.fit(\n",
    "    {\"training\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, \n",
    "    logs=True, job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c25152",
   "metadata": {},
   "source": [
    "As we did before, we deploy a model for inference and then generate predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73732b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-west-1-378421839225/tabular-training/output/jumpstart-pytorch-tabtransformerclassif-2023-07-29-19-34-53-229/output/model.tar.gz), script artifact (s3://jumpstart-cache-prod-us-west-1/source-directory-tarballs/pytorch/inference/tabtransformerclassification/v1.0.2/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-west-1-378421839225/sagemaker-jumpstart-2023-07-29-19-42-26-705/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: sagemaker-jumpstart-2023-07-29-19-42-26-705\n",
      "INFO:sagemaker:Creating endpoint-config with name jumpstart-inference-pytorch-tabtransfor-2023-07-29-19-42-26-705\n",
      "INFO:sagemaker:Creating endpoint with name jumpstart-inference-pytorch-tabtransfor-2023-07-29-19-42-26-705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-inference-{train_model_id}\")\n",
    "\n",
    "# Use estimator with best hyperparameters from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tabular_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0919aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "test_df = pd.read_csv(TEST_DATA)\n",
    "test_df['EJ_B'] = (test_df['EJ'] == 'B').astype('int')\n",
    "X_test = test_df.drop(columns=['Id', 'EJ'])\n",
    "\n",
    "df_test = pd.concat([X_test], axis=1)\n",
    "df_test.columns = [f\"Feature_{i}\" for i in range(df_test.shape[1])]\n",
    "\n",
    "# prepare the predicting features to send into the endpoint.\n",
    "features = df_test.iloc[:, :]\n",
    "\n",
    "# make predictions\n",
    "query_response_batch = query_endpoint(\n",
    "    features.iloc[:, :].to_csv(header=False, index=False).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "predict_prob = parse_response(query_response_batch)  # prediction probability per batch\n",
    "predict_label = np.argmax(predict_prob, axis=1)\n",
    "\n",
    "# store the test-set predictions in csv format, locally.\n",
    "pd.DataFrame(predict_prob).to_csv(\"test_pred_probs/amzn-tab-trans.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99162f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: sagemaker-jumpstart-2023-07-29-19-42-26-705\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: jumpstart-inference-pytorch-tabtransfor-2023-07-29-19-42-26-705\n",
      "INFO:sagemaker:Deleting endpoint with name: jumpstart-inference-pytorch-tabtransfor-2023-07-29-19-42-26-705\n"
     ]
    }
   ],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
