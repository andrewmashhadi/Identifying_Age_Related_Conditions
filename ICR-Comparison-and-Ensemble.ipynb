{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83699d31",
   "metadata": {},
   "source": [
    "# ICR - Identifying Age-Related Conditions\n",
    "## Using Machine Learning to detect conditions with measurements of anonymous characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c0391",
   "metadata": {},
   "source": [
    "In this notebook, we evaluate the validation results from the trained models: \n",
    "\n",
    "* **TabTransformer** w/ SMOTE\n",
    "* **SVM** w/ SMOTE\n",
    "* **XGBoost** w/ SMOTE\n",
    "\n",
    "We first load in the validation probability estimates from each model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbe781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load validation results\n",
    "TABTR_VAL_PROBS = pd.read_csv('val_pred_probs/amzn-tab-trans.csv').to_numpy()\n",
    "SVM_VAL_PROBS = pd.read_csv('val_pred_probs/svm-tuned.csv').to_numpy()\n",
    "XGB_VAL_PROBS = pd.read_csv('val_pred_probs/xgboost-tuned.csv').to_numpy()\n",
    "\n",
    "# load training results\n",
    "TABTR_TRAIN_PROBS = pd.read_csv('train_pred_probs/amzn-tab-trans.csv').to_numpy()\n",
    "SVM_TRAIN_PROBS = pd.read_csv('train_pred_probs/svm-tuned.csv').to_numpy()\n",
    "XGB_TRAIN_PROBS = pd.read_csv('train_pred_probs/xgboost-tuned.csv').to_numpy()\n",
    "\n",
    "# include paths to data from local storage location\n",
    "TRAIN_DATA = os.environ['DATAFILES_PATH'] + '/ICR_Competition/' + 'train.csv'\n",
    "\n",
    "# load training data\n",
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# allocate\n",
    "X = train_df.drop(columns=['Class', 'Id'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "y = train_df['Class'].astype(int)\n",
    "\n",
    "# train-validation split \n",
    "X_train_raw, X_val, y_train_raw, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_val['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_val = X_val.fillna(value=X_train_raw.mean())\n",
    "\n",
    "X_train_raw['EJ_B'].fillna(value=X_train_raw['EJ_B'].mode())\n",
    "X_train_raw = X_train_raw.fillna(value=X_train_raw.mean())\n",
    "\n",
    "# over sample the diagnosed patients in training set\n",
    "oversample = SMOTE(random_state=77, sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "# shuffle (in case the model choice may be impacted by ordering)\n",
    "np.random.seed(77)\n",
    "shuff_ind = np.random.choice(len(y_train), len(y_train), replace=False)\n",
    "\n",
    "X_train = X_train.iloc[shuff_ind,]\n",
    "y_train = y_train.iloc[shuff_ind,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257aba8",
   "metadata": {},
   "source": [
    "Define Balanced Logarithmic Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafbe217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_log_loss(p, y):\n",
    "    ind0 = np.where(y==0)[0]\n",
    "    ind1 = np.where(y==1)[0]\n",
    "    \n",
    "    N0 = len(ind0)\n",
    "    N1 = len(ind1)\n",
    "    \n",
    "    y0 = (y==0).astype(int)\n",
    "    y1 = y.astype(int)\n",
    "    \n",
    "    return (- np.sum(y0*np.log(p[:, 0]))/N0 - np.sum(y1*np.log(p[:, 1]))/N1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8242a5",
   "metadata": {},
   "source": [
    "Compare individual validation results from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b884c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "***************************************************************************\n",
      "Test Accuracy for TabTransformer: 0.9355\n",
      "Testing Balanced Logarithmic Loss for TabTransformer: 0.1302\n",
      "***************************************************************************\n",
      "***************************************************************************\n",
      "Test Accuracy for SVM: 0.8710\n",
      "Testing Balanced Logarithmic Loss for SVM: 0.3855\n",
      "***************************************************************************\n",
      "***************************************************************************\n",
      "Test Accuracy for XGBoost: 0.9677\n",
      "Testing Balanced Logarithmic Loss for XGBoost: 0.2356\n",
      "***************************************************************************\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(np.argmax(TABTR_VAL_PROBS, 1)==y_val)\n",
    "bll = bal_log_loss(TABTR_VAL_PROBS, y_val)\n",
    "\n",
    "print(75*\"*\")\n",
    "print(75*\"*\")\n",
    "print(f'Test Accuracy for TabTransformer: {acc:.4f}')\n",
    "print(f'Testing Balanced Logarithmic Loss for TabTransformer: {bll:.4f}')\n",
    "print(75*\"*\")\n",
    "\n",
    "acc = np.mean(np.argmax(SVM_VAL_PROBS, 1)==y_val)\n",
    "bll = bal_log_loss(SVM_VAL_PROBS, y_val)\n",
    "\n",
    "print(75*\"*\")\n",
    "print(f'Test Accuracy for SVM: {acc:.4f}')\n",
    "print(f'Testing Balanced Logarithmic Loss for SVM: {bll:.4f}')\n",
    "print(75*\"*\")\n",
    "\n",
    "acc = np.mean(np.argmax(XGB_VAL_PROBS, 1)==y_val)\n",
    "bll = bal_log_loss(XGB_VAL_PROBS, y_val)\n",
    "\n",
    "print(75*\"*\")\n",
    "print(f'Test Accuracy for XGBoost: {acc:.4f}')\n",
    "print(f'Testing Balanced Logarithmic Loss for XGBoost: {bll:.4f}')\n",
    "print(75*\"*\")\n",
    "print(75*\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0667a1",
   "metadata": {},
   "source": [
    "Try combining the output probabilites to create the *ensemble* model. First we try averaging the probability outputs from our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc41c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Averaging Ensemble: 0.9677\n",
      "Testing Balanced Logarithmic Loss for Averaging Ensemble: 0.1943\n"
     ]
    }
   ],
   "source": [
    "# concatenate the probability of positives from each model (train set)\n",
    "train_probs_df = np.concatenate((TABTR_TRAIN_PROBS[:, 1:], SVM_TRAIN_PROBS[:, 1:], XGB_TRAIN_PROBS[:, 1:]), axis=1)\n",
    "\n",
    "# concatenate the probability of positives from each model (validation set)\n",
    "val_probs_df = np.concatenate((TABTR_VAL_PROBS[:, 1:], SVM_VAL_PROBS[:, 1:], XGB_VAL_PROBS[:, 1:]), axis=1)\n",
    "\n",
    "# averaging results\n",
    "final_probs_avging = np.mean(val_probs_df, axis=1)[:, np.newaxis]\n",
    "final_probs_avging = np.concatenate((1-final_probs_avging, final_probs_avging), axis=1)\n",
    "\n",
    "# check new accuracy\n",
    "acc = np.mean(np.argmax(final_probs_avging, 1)==y_val)\n",
    "\n",
    "# check new balanced logarithmic loss\n",
    "bll = bal_log_loss(final_probs_avging, y_val)\n",
    "\n",
    "print(f'Test Accuracy for Averaging Ensemble: {acc:.4f}')\n",
    "print(f'Testing Balanced Logarithmic Loss for Averaging Ensemble: {bll:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5a1a1",
   "metadata": {},
   "source": [
    "Second, we try using logistic regression to generate a new probabilty estimate from the transformation of the linear combination of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3a4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Logistic Regression Ensemble: 0.9677\n",
      "Testing Balanced Logarithmic Loss for Logistic Regression Ensemble: 0.1578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_mod = LogisticRegression()  # regularization by default in sklearn\n",
    "lr_mod.fit(train_probs_df, y_train)\n",
    "\n",
    "# collect new validation probabilities \n",
    "probs = lr_mod.predict_proba(val_probs_df)\n",
    "\n",
    "# collect new validation accuracy \n",
    "acc = np.mean(np.argmax(probs, 1) == y_val)\n",
    "\n",
    "# collect new validation balanced logarithmic loss\n",
    "bll = bal_log_loss(probs, y_val)\n",
    "\n",
    "print(f'Test Accuracy for Logistic Regression Ensemble: {acc:.4f}')\n",
    "print(f'Testing Balanced Logarithmic Loss for Logistic Regression Ensemble: {bll:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0c0c5",
   "metadata": {},
   "source": [
    "We can see above that the probability outputs from the ensemble demonstrates a small balanced logarithmic loss at about 0.2403."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa20b1",
   "metadata": {},
   "source": [
    "### Output Probabilties \n",
    "\n",
    "We now generate the probabilites for the test set (for submission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2aedb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set results\n",
    "TABTR_TEST_PROBS = pd.read_csv('test_pred_probs/amzn-tab-trans.csv').to_numpy()\n",
    "SVM_TEST_PROBS = pd.read_csv('test_pred_probs/svm-tuned.csv').to_numpy()\n",
    "XGB_TEST_PROBS = pd.read_csv('test_pred_probs/xgboost-tuned.csv').to_numpy()\n",
    "\n",
    "# concatenate the probability of positives from each model (test set)\n",
    "test_probs_df = np.concatenate((TABTR_TEST_PROBS[:, 1:], SVM_TEST_PROBS[:, 1:], XGB_TEST_PROBS[:, 1:]), axis=1)\n",
    "\n",
    "# train LR model again\n",
    "lr_mod = LogisticRegression()  # regularization by default in sklearn\n",
    "lr_mod.fit(np.concatenate((train_probs_df, val_probs_df), axis=0), np.concatenate((y_train, y_val), axis=0))\n",
    "\n",
    "# collect test probabilities \n",
    "probs = lr_mod.predict_proba(test_probs_df)\n",
    "\n",
    "# store the test-set predictions in csv format, locally.\n",
    "pd.DataFrame(probs).to_csv(\"test_pred_probs/log-reg-ensemble.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
